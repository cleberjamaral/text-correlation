b'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSAT for Epistemic Logic using Belief Bases\\n\\nFabia\\xcc\\x81n Romero1 and Emiliano Lorini1\\n\\nIRIT, Toulouse France\\n\\nAbstract. In [1] a new epistemic logic LDA of explicit and implicit be-\\nliefs was introduced, and in [2] we presented a tableau-based satisfabil-\\nity checking procedure as well as a dynamic extension for LDA. Based\\non such procedure, we created a portable software implementation that\\nworks for the family of multi-agent epistemic logics, as well as for the\\nproposed dynamic extension. This software implementation runs as a li-\\nbrary for the most common operative systems, also runs in popular IoT\\nand robot hardware, as well as cloud environments and in server-less\\nconfigurations.\\n\\n1 Introduction\\n\\nWe believe that semantics based on explicit representation of agents\\xe2\\x80\\x99 epistemic\\nstates expressed as knowledge or belief bases, are a more natural paradigm for the\\ndescription of intelligent systems such as robotic and conversational agents than\\nthe Kripkean semantics commonly used for epistemic logics [4]. We implemented\\nthe tableau-based satisfability procedure for LDA given in [2] in order to have a\\ntool to experiment with such semantics and explore its use.\\n\\n2 Syntax and semantics\\n\\nThe language LLDA is constructed in the following way. Assume a countably\\ninfinite set of atomic propositions Atm = {p, q, . . .} and a finite set of agents\\nAgt = {1, . . . , n}.\\n\\nThe language L0, is the language of explicit beliefs defined by the grammar:\\n\\n\\xce\\xb1 ::= \\xce\\xb3 | 4i\\xce\\xb1\\n\\nWhere \\xce\\xb3 is the grammar of classical propositional logic. The multi-modal oper-\\nator 4i\\xce\\xb1 is read as \\xe2\\x80\\x9c\\xce\\xb1 is a formula on agent\\xe2\\x80\\x99s i belief base\\xe2\\x80\\x9d. The language of\\nimplicit beliefs LLDA is defined by the grammar:\\n\\n\\xcf\\x86 ::= \\xce\\xb1 |\\xef\\xbf\\xbdi\\xcf\\x86 | \\xe2\\x99\\xa6i\\xcf\\x86\\n\\nWhere \\xce\\xb1 \\xe2\\x88\\x88 L0 And the \\xef\\xbf\\xbdi\\xcf\\x86 modality can be read as \\xe2\\x80\\x9cagent i can deduce \\xcf\\x86 from\\nits belief base\\xe2\\x80\\x9d and the modal dual \\xe2\\x99\\xa6i\\xcf\\x86 as \\xe2\\x80\\x9c\\xcf\\x86 is consistent with agent i belief\\nbase\\xe2\\x80\\x9d.\\n\\nlouisedennis\\nPlaced Image\\n\\n\\n\\n2 Lorini E, Romero F\\n\\nThe dynamic extension of LDA we present in our companion paper, allow us\\nto describe actions of agents under observability conditions, this perceptive con-\\ntext, where the dynamic actions take place is defined by the following grammar\\nLOBS:\\n\\n\\xcf\\x89 ::= seei,j | seei\\xcf\\x89\\nThe expression seei,j Can be read as \\xe2\\x80\\x9cagent i sees what agent j does\\xe2\\x80\\x9d. And\\n\\nseei\\xcf\\x89 represents the fact that \\xe2\\x80\\x9cagent i sees that \\xcf\\x89\\xe2\\x80\\x9d.\\nThe language LDLDA is defined by the following grammar:\\n\\n\\xcf\\x87 ::= \\xc2\\xac\\xcf\\x87 | \\xcf\\x871 \\xe2\\x88\\xa7 \\xcf\\x872 | [(p, \\xcf\\x84, i, \\xe2\\x84\\xa6)]\\xcf\\x87 | \\xcf\\x86\\n\\nWhere p is a proposition, i \\xe2\\x88\\x88 Agt , \\xcf\\x86 ranges over the language LLDA ,\\xcf\\x84 ranges\\nover {+,\\xe2\\x88\\x92} and \\xe2\\x84\\xa6 is a finite set of formulas of LOBS.\\n\\nThe action +p consists in setting the value of the atomic variable p to true,\\nwhereas the action \\xe2\\x88\\x92p consists in setting the value of the atomic variable p to\\nfalse. The formula [(p, \\xcf\\x84, i, \\xe2\\x84\\xa6)]\\xcf\\x86 has to be read \\xe2\\x80\\x9c\\xcf\\x86 holds after the performance\\nof the action \\xcf\\x84p by agent i in the perceptive context \\xe2\\x84\\xa6\\xe2\\x80\\x9d.\\n\\n2.1 Input syntax\\n\\nThe syntax used for the library is the following. Operations and precedence order\\nfor unparenthesized expressions in LLDA are:\\n\\nfalse := false, F,\\xe2\\x8a\\xa5\\ntrue := true, T,>\\n\\nbox operator agent j := [j],\\xef\\xbf\\xbdj\\n\\ndiamond operator agent j := < j >,\\xe2\\x99\\xa6j\\n\\ntriangle operator agent j := {j},4j\\nnegation := \\xe2\\x88\\x92,\\xe2\\x88\\xbc,\\xc2\\xac\\n\\nconjunction := &,\\xe2\\x88\\xa7, /\\\\,\\xcc\\x82\\ndisjunction := \\xe2\\x88\\xa8, \\\\/, |\\nimplication := \\xe2\\x88\\x92 >,\\xe2\\x86\\x92\\n\\ndouble implication := < \\xe2\\x88\\x92 >,\\xe2\\x86\\x94\\nconjunction := ;\\n\\nPropositions are strings of lowercase letters of length greater than zero, fol-\\nlowed by zero or more digits, agents are strings of digits of length greater than\\nzero.\\n\\nWe represent seei,j in LOBS as \\xe2\\x80\\x9ci < j\\xe2\\x80\\x9d with infix right associative operator\\n\\xe2\\x80\\x9c<\\xe2\\x80\\x9d as . We use \\xe2\\x80\\x9c;\\xe2\\x80\\x9d to separate observations in a perceptive context, and for\\nthe dynamic operator introduced as: [(p, \\xcf\\x84, i, \\xe2\\x84\\xa6)] we will use i + p or i \\xe2\\x88\\x92 p to\\nrepresent the Boolean value of the variable p for the agent i. And \\xe2\\x80\\x9c[(\\xe2\\x80\\x9d, \\xe2\\x80\\x9c)]\\xe2\\x80\\x9d\\nwill be used to open and close the definition of the operator. For example, if\\n\\xe2\\x84\\xa6 = {seei,i, seej,i, seeiseej,i}. Then the LDLDA operator [(p,+, i, \\xe2\\x84\\xa6)] is written\\nas:\\n\\n\\n\\nSAT for Epistemic Logic using Belief Bases 3\\n\\n[(i+p;i<i;j<i;i<j<i)]\\n\\nFor readability, we allow comments starting from a character \\xe2\\x80\\x99#\\xe2\\x80\\x99 to the end\\nof the line, and all contiguous white space characters including new lines are\\ninterpreted as a single space.\\n\\n3 Example\\n\\nThe example consists in a simple scenario of human-robot interaction from the\\nfamous Sally-Anne false belief\\xe2\\x80\\x99s task from the psychological literature on Theory\\nof Mind [5]. As discussed on our companion paper [2].\\n\\nWe assume that Agt = {1, 2} where 1 denotes a human and 2 denotes a\\nrobot. The human and the robot are standing in front of each other on the\\nopposite sides of a table. The robot has a black ball, a grey ball, and two boxes\\nin front of him. Initially, the human has not previous knowledge of the setting,\\nand the robot, doesn\\xe2\\x80\\x99t has any knowledge about the human\\xe2\\x80\\x99s knowledge. Then,\\nthe robot puts the black ball inside the box no.2, while it is aware that the\\nhuman is watching his actions. And the robot believes that the human believes\\nthat if a ball is in a given box, then that ball is not in the other box. From this\\nsetting, the robot should be able to deduce that the human believes that the\\nblack ball is not in box no.1.\\n\\n# Observe the semicolon \\xe2\\x80\\x99;\\xe2\\x80\\x99 means conjunction (with the least precendence)\\n\\n# it is convenient as we usually create belief bases on conjunctive form.\\n\\n#Hypotesis 1\\n\\n-{1}b1 & -{1}b2; # Human doesn\\xe2\\x80\\x99t explicitly believe either ball\\n\\n-{1}g1 & -{1}g2; # is in either box\\n\\n-{2}{1}b1 & -{2}{1}b2; # Robot doesn\\xe2\\x80\\x99t explicitly believe the human believe\\n\\n-{2}{1}g1 & -{2}{1}g2; # if either ball is in either box\\n\\n#Hypotesis 2\\n\\n{2}({1}b1->{1}-b2; # Robot explicitly believes that\\n\\n{1}b2->{1}-b1; # if human believes any ball is in either box\\n\\n{1}g1->{1}-g2; # then it also believes that such ball is not\\n\\n{1}g1->{1}-g2); # in the other box (here enumerated the 4 options)\\n\\n# As usual with SAT, we use the negation of the formula we want to\\n\\n# test, because, if the negation is unsatisfiable, the formula holds\\n\\n# The observation context is both observing each other\\n\\n# and simultaneosly aware of this fact and of themselves\\n\\n-[( 2+b2; 1<1; 2<2; 1<2; 2<1; 1<2<1; 2<1<2 )]( # We set b2 true for the robot\\n\\n({2}b2) & ({1}b2) & ({2}{1}b2);# All aware that black ball is in box 2\\n\\n[2]{1}-b1 # Robot can conclude that human belives ...\\n\\n) # ... that the black ball is not in box 1\\n\\nWhich of course, after evaluating the translation, returns that is unsatisfiable.\\nThe tool is available for testing at https://tableau.irit.fr.\\n\\nhttps://tableau.irit.fr\\n\\n\\n4 Lorini E, Romero F\\n\\n4 Implementation\\n\\n4.1 Software, Architecture and algorithms\\n\\nWe created a tool in the F] programming language (an open source, cross plat-\\nform ML language for the Common Language Infrastructure (CLI)), that follows\\nclosely the paper as reference implementation, with the following speed improve-\\nments.\\n\\nThere are two separated API methods, one for the reduction of the dynamic\\nextension, and the second for the evaluation of the satisfability given by the\\ntableau procedure.\\n\\nFor the reduction of the dynamic extension, we implement the exact rewriting\\nas specified in the paper, with no further optimization.\\n\\nFor the propositional case, we added a modern yet simple DPLL SAT solver,\\nwe focused more in having a clean and solid functional architecture for this rather\\nthan adding all possible heuristics, it is slower (2x-50x) than other modern SAT\\nsolver (We benchmarked against Z3 [3]), and also is much simpler (the current\\nimplementation of the SAT solver has less than 1k lines of code). However, is\\nwritten in F], so it is exactly as portable as the library itself, which simplifies\\nenormously the development/testing and integration as compared as using a\\nC+ + library which is the language most modern SAT solvers are implemented.\\nThis solver is used to discard processes, but the solution when available, is given\\nby the tableau itself. So this is only used to help speed up execution, and it can\\nbe disabled when calling the library.\\n\\nWe use a reactive asynchronous execution workflow that allows us to aggres-\\nsively benefit from hardware parallelism when available.\\n\\nWe create a process tree which is the contraction of the tableau tree on the\\nroot node and all nodes created by applying a transitional rule. Each process runs\\na \\xe2\\x80\\x9cSAT solver\\xe2\\x80\\x9d for the propositional interpretation of the set of variables, and\\nspawns one process for each transitional rule that would apply to the contracted\\ntableau node. If the \\xe2\\x80\\x9cSAT solver\\xe2\\x80\\x9d is not satisfiable or any of the children sends\\na message saying it is unsatisfiable, it kills all remaining children and returns\\nwith the same message to its father. In other case, when all transitional children\\nreturn a satisfactory configuration, it returns itself with the appropriate message\\nto its father.\\n\\nAs we use immutable data structures, we can use shared memory between\\nprocesses, in a safe and fast manner.\\n\\nIt is written entirely for the .net core platform, which runs in an array of\\narchitectures and operative systems, that include RaspberyPi, Linux, MacOs,\\nWindows and the Windows 10 IoT which is rapidly increasing the array of hosts.\\n\\nA trade off for the current version, is that we use a full in-memory approach.\\nSo, it runs well with models having few thousands of \\xe2\\x80\\x9cmodal\\xe2\\x80\\x9d tableau nodes and\\nfew million propositional variables among them, but fails in much larger models,\\nwhich we consider is acceptable for the kind of environments/problems the tool\\nis designed for.\\n\\n\\n\\nSAT for Epistemic Logic using Belief Bases 5\\n\\nReferences\\n\\n1. Lorini, E. 2018a. In praise of belief bases: Doing epistemic logic without possible\\nworlds. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelli-\\ngence, 19151922. AAAI Press\\n\\n2. Lorini, E., Romero, F. 2019a. Decision Procedures for Epistemic Logic Exploiting\\nBelief Bases. Conference 2019 AAMAS.\\n\\n3. De Moura, Leonardo and Bjrner, Nikolaj. 2008. Z3: an efficient SMT solver. In:\\nTools and Algorithms for the Construction and Analysis of Systems, pp227-340\\n\\n4. Fagin, R.; Halpern, J.; Moses, Y.; and Vardi, M. 1995. Reasoning about Knowledge.\\nCambridge: MIT Press.\\n\\n5. S. Baron-Cohen AND A. M. Leslie AND U. Frith. 1985. Does the autistic child have\\na \\xe2\\x80\\x9ctheory of mind\\xe2\\x80\\x9d?. Ignition 21 pp36-46\\n\\n\\n\\tSAT for Epistemic Logic using Belief Bases\\n\\n'