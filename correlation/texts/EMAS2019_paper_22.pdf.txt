b'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAn Architecture for Integrating BDI Agents\\nwith a Simulation Environment\\n\\nAlan Davoust2,1, Patrick Gavigan1, Cristina Ruiz-Martin1, Guillermo\\nTrabes1,3, Babak Esfandiari1, Gabriel Wainer1, and Jeremy James4\\n\\n1 Carleton University, Ottawa, Canada\\npatrickgavigan,cristinaruizmartin,guillermotrabes,babak,gwainer@sce.carleton.ca\\n\\n2 Universite\\xcc\\x81 du Que\\xcc\\x81bec en Outaouais, Gatineau, Canada\\nalan.davoust@uqo.ca\\n\\n3 Universidad Nacional de San Luis, Argentina\\n4 Cohort Systems\\n\\njjames@cohortsys.com\\n\\nAbstract. We present Simulated Autonomous Vehicle Infrastructure\\n(SAVI), an open source architecture for integrating Belief-Desire-Intention\\n(BDI) agents with a simulation platform. This approach decouples the\\ndevelopment of complex multi-agent behaviours from the development\\nof simulated environments to test them in.\\nWe identify and address the impedance mismatch between modelling\\nand simulation and BDI systems. Our approach avoids linking the en-\\nvironment\\xe2\\x80\\x99s simulation time step to the agents\\xe2\\x80\\x99 reasoning cycles: if the\\nagents\\xe2\\x80\\x99 reasoning is slow, perhaps due to expensive computations, the\\nsimulation will continue unaffected. Conversely, SAVI also prevents the\\nreasoning from running faster than the simulation.\\nBoth of these situations should be impossible for simulated environments\\nthat are meant to approximate the dynamic and continuous time nature\\nof the real world. This is accomplished by running the simulation cycles\\nand the agent reasoning cycles each in their own threads of execution,\\nand managing a single point of contact between these threads. Finally,\\nwe illustrate the use of our architecture with a case study involving the\\nsimulation of Unmanned Aerial Vehicles (UAVs) following birds.\\n\\nKeywords: Belief-Desire-Intention (BDI) \\xc2\\xb7 Modeling and Simulation \\xc2\\xb7\\nArchitecture \\xc2\\xb7 Jason \\xc2\\xb7 AgentSpeak Language (ASL)\\n\\n1 Introduction\\n\\nMulti-agent systems are often designed to be embedded in highly dynamic envi-\\nronments. In these environments, the wide range of possible input signals may\\nproduce complex group-level behaviours which are difficult to accurately pre-\\ndict or to produce by design. During the development process, the behaviour\\nof the agents must therefore be thoroughly tested in a controlled yet realistic\\nenvironment before the system can be deployed. In this research, we are con-\\ncerned with the development of agents using the Belief-Desire-Intention (BDI)\\n\\nlouisedennis\\nPlaced Image\\n\\n\\n\\n2 Davoust, Gavigan et al.\\n\\nparadigm [24], and of an appropriate simulated environment to test the agent\\nsystem. The main challenge in this task is the lack of frameworks to appropri-\\nately handle both the development of complex cognitive agents and of a realistic\\nsimulated environment[27, 1].\\n\\nExisting BDI frameworks, such as Jason [14, 10] and lightJason [4, 18], in-\\nclude simple environments that can be reused and extended, but these envi-\\nronments lack the sophistication and graphical capabilities of proper simula-\\ntion platforms. Conversely, the field of Modelling and Simulation provides a set\\nmethodologies with their own simulation tools (e.g. the Discrete Event System\\nSpecification (DEVS) formalism [35] with simulators including CD++ [33] and\\nPyDEVS [28], Agent Based Modelling (ABM) with tools including Repast[22] or\\nNetLogo [34]). It also provides domain specific simulation platforms for commu-\\nnication networks (e.g. OMNET++ [32]), traffic simulation (e.g. MITSIMLab\\n[7], Microscopic Traffic Simulator [17]), and other domains. However, these are\\npoorly suited for modelling complex cognitive processes [1]; in particular, they\\ndo not provide any support for techniques such as BDI.\\n\\nAs a result, the main approaches to integrating these two pieces involve either\\nwriting custom simulation code in a BDI framework, or custom BDI support in\\na simulation platform, or finally integrating two separate, mature frameworks\\nfrom the two areas, with a considerable impedance mismatch problem [27]. By\\nthis term we refer to the conceptual and technical issues faced when integrating\\ncomponents defined using different methodologies, formalisms or tools.\\n\\nOur work follows the third approach, and aims to integrate BDI agents with a\\nsimulated environment. Our main contribution is Simulated Autonomous Vehicle\\nInfrastructure (SAVI), an architecture that seamlessly connects the Jason BDI\\nframework [14, 10] with a simulation environment developed using Processing\\n[13], addressing several key elements of the impedance mismatch problem.\\n\\nIn particular, our architecture decouples the agents from the simulation en-\\nvironment, making it easy to develop them independently, and allowing them to\\nrun as separate processes interacting in an asynchronous manner. This avoids\\nlinking the environment\\xe2\\x80\\x99s simulation advances to the agent\\xe2\\x80\\x99s responses: if the\\nagent is for some reason slow (e.g. due to expensive computation), the simula-\\ntion will continue unaffected, making the transition to a natural environment\\nmore realistic.\\n\\nThe rest of the paper is organized as follows: in section 2 we provide a sum-\\nmary of background followed by related work in section 3. This is followed by\\na definition of the proposed SAVI architecture is in section 4. In section 5 we\\ndescribe a case study applying our architecture. Finally, we conclude in section\\n6 followed by a brief section on future work.\\n\\n2 Background\\n\\nIn this section we present the BDI paradigm for developing multi-agent systems\\nand discuss different approaches to develop a BDI agent system in a simulated\\nenvironment.\\n\\n\\n\\nAn Architecture for Integrating BDI Agents with a Simulation Environment 3\\n\\n2.1 Belief-Desire-Intention Architecture\\n\\nThe BDI architecture was introduced by Bratman and others in the 1980s[11]\\nas a way to develop complex intelligent and autonomous agents. In this method,\\nagents have a set of beliefs, stored in a belief base about their state as well as the\\nstate of their environment. They can perceive their environment to update these\\nbeliefs. These agents also have goals, or desires, that they need to achieve. The\\nagents also have a set of plans that they can execute, stored in a plan base. The\\nplans can involve updates to the belief base, or actions that the agent can apply to\\nthe environment. When an agent reasons about its beliefs and desires and selects\\nan appropriate plan to execute, this plan becomes an intention. As the agent\\nexecutes these plans, the agent can drop intentions based on changes in their\\nbeliefs if they are no longer achievable due to some change in the environment.\\nThe execution cycle for a BDI agent, from perception to action, is called the\\nreasoning cycle.\\n\\nBDI architectures have become especially relevant with the development of\\nautonomous vehicles, in particular, self-driving cars (see [25] for example). How-\\never, as testing the vehicles\\xe2\\x80\\x99 decision-making in a real-life setting is challenging,\\nit is crucial that they can be developed in a realistic simulated environment.\\n\\n2.2 Simulation Requirements for Multi-Agent Systems\\n\\nA multi-agent system is situated in an environment (real or simulated) which\\nthe agents can perceive through different types of sensors (e.g. a camera or lidar\\nsensor), and modify through actuators (e.g. moving to a new location, picking\\nup an object).\\n\\nAn important property of the environment is whether it is static or dynamic\\n[26]: a static environment contains only static objects that remain fixed and\\nunchanging (the agents change only their internal state); a simple dynamic en-\\nvironment changes over time, but only due to the agents\\xe2\\x80\\x99 actions; and finally\\na complex dynamic environment changes over time, due to the agents\\xe2\\x80\\x99 actions\\nbut also due to other external factors, including natural phenomena, and agents\\noutside of the considered agent system (e.g. humans).\\n\\nThe actions performed by the agents and the changes to the environment,\\neither in response to the agents\\xe2\\x80\\x99 actions or due to external factors, update the\\nstate of the system over time. There are several ways to model time in a sim-\\nulation. One approach, Discrete-Event Modelling [5], updates the model\\xe2\\x80\\x99s state\\nvariables every time an event occurs, and allows the model (or each sub-model\\nof a composite model) to schedule its next state change, at any time. This allows\\narbitrarily fine-grained precision along the time axis. In an alternative approach,\\nDiscrete Time Modelling, the state of the simulation is updated at discrete points\\nin time. The difference between a point in time and the next one is called the\\ntime step. This approach is well suited for applications where the system state\\nchanges very quickly or many events happen in a short period of time.\\n\\n\\n\\n4 Davoust, Gavigan et al.\\n\\n3 Related Work: Simulated Environments for BDI\\nsystems\\n\\nThere are three main approaches to simulate the environment of a BDI agent\\nsystem [27]: the simulation can be built into the BDI engine, or else an existing\\nsimulation platform can be extended to support BDI, or finally a simulation\\nplatform can be connected to a BDI engine.\\n\\n3.1 Simulation within MAS development platforms\\n\\nSeveral agent development platforms have basic built-in simulation capabilities;\\nthis includes BDI platforms such as Jason.\\n\\nIn [9], the authors provide their own custom simulation environment for\\nBDI agents. Another such custom simulation is [31], which includes heavyweight\\nagents (i.e. agents with very advanced reasoning) combined with lightweight\\nagents (i.e. agents that only reacts to their environment). However, if we com-\\npare these custom environments to other simulator platforms such as Repast,\\ntheir features and capabilities are very limited. Typically, they are meant to sup-\\nport simple dynamic environments (which only change according to the agents\\xe2\\x80\\x99\\nactions), and do not explicitly model time.\\n\\n3.2 Modelling cognitive processes in simulation platforms\\n\\nThe second approach is to model the cognitive capabilities of agents (BDI, in\\nour case) on standard simulation platforms.\\n\\nEstablished ABM modeling tools (such as Netlogo or Repast) are not meant\\nto directly model complex agent behaviours or realistic physical systems: their\\nstrength is rather in modelling the behaviour of complex systems as the emer-\\ngent result of very simple interacting agent models. Similarly, general-purpose\\nsimulation systems (e.g. Mason [19]) and formalisms (e.g. DEVS) do not have\\nbuilt-in capabilities to model cognitive processes (such as the basic machinery of\\nthe BDI paradigm). However, there have been several attempts to build models\\nof cognitive processes using modelling and simulation formalisms, in particular\\nthe DEVS formalism.\\n\\nSeveral projects have implemented BDI reasoning with the DEVS formalism\\n[30, 29, 1, 36].\\n\\nJAMES [30, 29] is a Java Based agent modeling environment for simulation,\\nto be used as test beds for multi-agent systems. It allows the execution of agents\\nin distributed environments. In JAMES, an agent is represented as a DEVS\\natomic model, where its autonomous behaviour is represented by the internal\\nfunction and the perceptions are represented through the external function. The\\nactions of the agent in the environment are represented as the output function. In\\nJAMES, the BDI architecture is incorporated in the internal state of the atomic\\nmodel. Because in ABM, new agent are usually created and destroyed during\\nthe simulation, the authors also introduced Dynamic DEVS (DynDEVS).\\n\\n\\n\\nAn Architecture for Integrating BDI Agents with a Simulation Environment 5\\n\\nThe proposals of [1] and Zhang et al. [36] are very similar to the JAMES\\napproach. The former use the classic dynamic DEVS (DS-DEVS) introduced\\nby Barros [6] on a platform targeted at the simulation of agriculture called\\nRECORD[8], whereas the latter implement implement PRS[15], a BDI-based\\nreasoning architecture, on the D-SOL simulation platform[16]. Another model\\nof cognitive processes, ACT-R, has also been modelled with DEVS[20].\\n\\nDIVAs [3] is a simulation platform for dynamic and open environments that\\nincludes some machinery for agents\\xe2\\x80\\x99 cognitive processes, including base classes\\nto implement agent knowledge, tasks and plans. However, it is unclear whether\\nthis system uses an established simulation formalism or an established cognitive\\nreasoning model.\\n\\n3.3 Connecting simulation platforms and cognitive reasoning\\nengines\\n\\nA third approach, the one presented in this paper, aims to couple a mature\\nplatform for developing cognitive agents with an existing simulation platform.\\nThis can provide an improved modeling capability for simulations that involve\\ncomplex agent behaviors. The main existing work in this direction [23, 27] is\\nan integration of the commercial JACK platform [2] (for BDI agents) with the\\nRepast agent based simulation software [21]. This is then generalized to an ar-\\nchitecture that can accommodate wider range of ABM platforms and a wider\\nrange of platforms for modelling cognitive agents. The main weakness we see\\nin this architecture is that it involves synchronizing the discrete-time simula-\\ntion steps with the reasoning cycles of the cognitive agents. This implies that\\nincreasing the simulation granularity will also increase the relative speed of the\\nagent\\xe2\\x80\\x99s reasoning, since agents will be able to reason and act at much shorter\\ntime intervals of the simulation. In contrast, our approach allows the reasoning\\ncycles to be decoupled from the simulation clock, and potentially get left behind\\nby fast processes happening in the simulation.\\n\\nOur approach is similar, although we have chosen Processing [13] as a sim-\\nulation environment rather than an ABM tool. In our view, ABM modelling\\ntools (such as Netlogo or Repast) are poorly suited to model complex dynamic\\nenvironments. The agent-based modelling approach tends to model the entire\\nsystem of interest (including physical systems deprived of any agency) as a sys-\\ntem of (numerous) interacting agents. When the environment includes a small\\nnumber of complex cognitive agents and a small number of (potentially complex)\\nphysical systems, other modelling methodologies appear more appropriate. ABM\\nplatforms also do not typically support discrete-event simulation.\\n\\nOur choice of Processing is motivated by its powerful built-in visualization\\ncapabilities, and the option of using discrete-event simulation (although at this\\npoint our simulations are all discrete-time). A powerful graphical interface is\\nuseful for the demonstration of real scenarios to a non-technical audience. This\\nis specially important for our use case, a military application where we need\\nto test the resilience of the BDI agents. We note that we are also investigating\\n\\n\\n\\n6 Davoust, Gavigan et al.\\n\\nthe applicability of this architecture to other simulation platforms, including\\nMason [19].\\n\\n4 SAVI Architecture\\n\\nThis section details the proposed SAVI architecture for integrating BDI agents\\nwith a simulated environment. Specifically, we will focus on solving the problems\\nresulting from the impedance mismatch between BDI and simulation systems.\\nFirst, we introduce our framework setup, and briefly discuss the impedance mis-\\nmatch problems. Then we introduce the open source SAVI architecture [12] and\\nexplain how these problems are addressed.\\n\\n4.1 Setup\\n\\nOur overarching problem is to connect an agent system built with a BDI frame-\\nwork to a model of the environment, designed using a framework appropriate for\\nsimulation. In our case, the BDI framework is Jason [10, 14], and our simulation\\nruns in Processing [13]. Both are Java applications, which makes the integration\\nmanageable through direct method invocations, but the same approach would\\nbe feasible with any frameworks that expose the appropriate information via an\\nexternal Application Programming Interface (API).\\n\\nOur assumption is that the BDI agents are simply the reasoning engine (the\\nbrain) for agents with a physical presence in the simulated environment (e.g.,\\ndrones or unmanned vehicles). In our case (see case study in section 5), these\\nagent models are drones.\\n\\nIn order to connect the two \\xe2\\x80\\x9dworlds\\xe2\\x80\\x9d (i.e. simulation and BDI agents), the\\nagent brains must receive perceptions of the world from the simulated agents, and\\nsend actions for the agent models to execute in the simulated world. Eventually,\\nthese agent brains will be connected to physical agents transmitting the same\\ninformation as their simulated counterparts, and the goal is for the simulated\\nbehaviour to carry over into the real world.\\n\\n4.2 Decoupling simulation and reasoning\\n\\nIn this context, one approach (adopted for example by Singh et al. [27]) is to\\nuse the discrete-time simulation process as a driver for the agents\\xe2\\x80\\x99 reasoning:\\nat each time-tick, update each simulated model, and invoke one reasoning cycle\\nfrom the agent brains. This has the advantage of simplifying the integration\\nof the two platforms, but it arguably comes at a significant cost in terms of a\\nrealistic simulation. In particular, it implies that changing the simulation time\\nstep (simply to change the granularity of the simulation), would directly affect\\nthe agents\\xe2\\x80\\x99 reasoning clock : the agent reasoning will not be simulated more or\\nless precisely, it will instead directly increase or decrease the agent\\xe2\\x80\\x99s relative\\ncomputational power, by allowing unbounded time for each decision. Pushed\\nto the extreme, we might imagine for example an agent getting lost in thought\\n\\n\\n\\nAn Architecture for Integrating BDI Agents with a Simulation Environment 7\\n\\nwhile computing intractable plans, and the world would then wait for the agent.\\nOf course, this cannot happen in a real world environment: if an agent is lost in\\nthought, the environment will continue to update while the agent performs its\\nreasoning.\\n\\nTherefore, our approach allows the agents\\xe2\\x80\\x99 brains to run as their own pro-\\ncesses (threads, more specifically), while the simulation will update on its own\\nschedule. The two sides must now interact asynchronously, which brings several\\nchallenges (generically described above as the impedance mismatch between the\\ntwo frameworks).\\n\\nFor one thing, actions may be initiated by the agent asynchronously, whereas\\nthe simulation system constrains changes to happen at fixed time steps. This is\\nconnected to a thread-safety issue, if both an agent process and the simulation\\nprocess attempt to concurrently modify the environment.\\n\\nMore importantly, there is now a delicate balance to maintain between the\\nsimulation speed and the agents\\xe2\\x80\\x99 reasoning speed. On one hand, if the agent\\nreasons too fast, then it might repeatedly perceive an outdated state of the\\nworld and misinterpret the consequences of its latest action, which the simulation\\nengine has not yet computed. The problem here is that this would not happen\\nin the real world: there cannot be any delay between an action being initiated\\nby the an agent in the real world, and this action initiating its effect on the\\nenvironment. On the other hand, if the agent is slow and the perceptions from\\nthe environment come as messages, the agents might accrue a backlog of these\\nmessages, and again be attempting to act on an outdated perception of reality.\\nIn this case an agent being too slow to keep up with its environment is perfectly\\npossible. However, the environment would not be sending overwhelming numbers\\nof updates in the form of messages5.\\n\\n4.3 The SAVI Architecture\\n\\nIn order to address these challenges, we designed the SAVI architecture shown\\nin figure 1.\\n\\nFig. 1. Simulation and agent behaviour architecture.\\n\\n5 Of course, the perception infrastructure may do so, and again using the present\\narchitecture to implement that interface could solve the problem.\\n\\n\\n\\n8 Davoust, Gavigan et al.\\n\\nThis architecture uses three main modules for implementing the interface be-\\ntween the BDI agents and the simulation infrastructure. These include the Sim-\\nulated Environment module, the State Synchronization module, and the Agent\\nBehaviour module. To ensure that the simulation time step is independent of\\nthe agent reasoning cycle rate of each of the agents, the simulation engine and\\neach individual agent\\xe2\\x80\\x99s behavioural model run in separate threads of execution.\\n\\nThe Simulated Environment module is responsible for providing the simu-\\nlated environment as well as a simulated model of the agents\\xe2\\x80\\x99 physical presence\\nin that environment. This includes all movements and interactions of the agents.\\nIn our case, this module also provides a visualization of the environment for\\nmonitoring the simulation.\\n\\nIndividual agents perceive this simulated environment as well as their own\\nproperties, and perform actions. These interactions are mediated by the State\\nSynchronization module. This module is responsible for ensuring mutual exclu-\\nsion of the different execution processes over perception, messages, and actions\\nbeing passed between the environment and agent objects in the Agent Behaviour\\nmodule. This mutual exclusion is managed by ensuring that the variables rep-\\nresenting the agent\\xe2\\x80\\x99s perception are always calculated and set by the simulation\\nside and only read by the behavioural models. Mutual exclusion of data between\\nthe simulation and agent threads is ensured using thread safe variables, and hap-\\npens separately for each agent, meaning that there is no centralized bottleneck.\\n\\nThe agent behaviour module provides the implementation of the BDI based\\nbehaviour model. It receives environmental perceptions and messages from other\\nagents via the State Synchronization module and responds by sending actions\\nand messages back. These responses are determined using the BDI reasoning\\ncycle, which runs as a separate thread of execution for each agent. This enables\\nthe updates to the environment to be decoupled from the execution time of the\\nindividual reasoning cycles of each agent. In addition, since the perceptions are\\nrepresented as state variables to be read, as opposed to messages, there is never\\na backlog of perceptions waiting for the agent, even if the reasoning is slow.\\n\\nFinally, in the case where the agent reasons faster than the simulation can\\nupdate the environment variables, we ensure that the agent waits for new per-\\nceptions by implementing a producer-consumer pattern: if the simulation clock\\nhas not advanced since the previous reasoning cycle, the agent waits. For this\\npurpose, the simulation engine timestamps every update of the state variables.\\n\\nThe effects of this speed coordination are illustrated by measurements of the\\nsimulation update speed and the reasoning speed, discussed in section 5.4.\\n\\n5 Case Study\\n\\nIn this section, we describe our implementation of the SAVI architecture. We\\ndemonstrate the separation of the simulation from the implementation of the\\nagent behaviours in BDI. We also show that we have overcome the impedance\\nmismatch between these two techniques. Our case study scenario involves an\\nairport safety patrol made up of Unmanned Aerial Vehicles (UAVs) chasing\\n\\n\\n\\nAn Architecture for Integrating BDI Agents with a Simulation Environment 9\\n\\nmigratory birds away from the airport. The implementation of SAVI, including\\nthis case study, are available as an open-source project [12].\\n\\n5.1 Scenario\\n\\nIn this scenario, UAVs are controlled by BDI agents in order to chase migratory\\nbirds away from the airport property. The simulation environment represents the\\nOttawa airport area, the UAVs, and the different threats (migratory birds) that\\ncan appear in that area. Because the objective of the case study is to show our\\nsimulation architecture, and not necessarily to demonstrate the performance of\\ncomplex behaviours, we use a simplified version of the problem where the UAVs\\xe2\\x80\\x99\\nmission is simply to follow the different threats near the airport.\\n\\nEach UAV perceives the environment through four sensors:\\n\\n1. A Global Positioning System (GPS) receiver that provides the position of\\nthe UAV,\\n\\n2. A velocity sensor that indicates the UAV\\xe2\\x80\\x99s speed and direction of travel,\\n3. A camera that can see nearby threats and other UAVs up to a maximum\\n\\nrange,\\n4. A clock.\\n\\nEach UAV also has a set of simple actions related to moving in the environ-\\nment. These include:\\n\\n1. Turning to the left,\\n2. Turning to the right,\\n3. Activating a thruster to move forward,\\n4. Deactivating a thruster to stop moving.\\n\\nThe behavior of the UAVs in this simulation is defined in AgentSpeak Lan-\\nguage (ASL) as follows:\\n\\n\\xe2\\x80\\x93 When the UAV does not perceive any threats, the UAV stops and keep\\nturning until a threat is perceived.\\n\\n\\xe2\\x80\\x93 When the UAV perceives threats, it turns to face the nearest one and then\\nfollows it.\\n\\n5.2 Implementation\\n\\nThe simulation is built using Processing [13], which handles the set-up and\\ndiscrete-time simulation as well as visualisation. The agent behaviour to be de-\\nployed in the UAVs is defined using the BDI paradigm, with behaviours written\\nin the ASL and interpreted using Jason [10, 14]. These two components are in-\\ntegrated as described above, using our SAVI architecture. The threat behaviour\\nis directly implemented in Java: each threat sets a random destination and then\\ntravels in a straight line from its actual position. Once they arrive, they choose\\na new random destination.\\n\\n\\n\\n10 Davoust, Gavigan et al.\\n\\n5.3 Testing\\n\\nOur case study consists of two scenarios, which can be easily set up in the sim-\\nulation environment\\xe2\\x80\\x99s configuration file. In the first scenario, shown in figure 2,\\nwe simulated the Ottawa airport area with 10 bird threats. The area is patrolled\\nby three UAVs which have a limited camera perception range, as shown in the\\nfigure by a semicircle. Objects that are visible to a UAV are shown with circles\\naround them. In the figure we can see that all the UAVs have a threat within\\ntheir camera range; however, there is a large area that is not observed by the\\nUAVs.\\n\\nFig. 2. Scenario 1: Test bed with 3 UAVs with short perception distance and 10 threats.\\n\\nIn the second scenario, shown in figure 3, we simulated the Ottawa airport\\narea with 15 threats. The area was patrolled by 10 UAVs with longer-range\\ncameras, also represented by a semicircle in the figure. In the figure we can see\\nthat all the threats are perceived at least by one UAV. Likewise, all the UAVs\\nare perceived by at least another UAV, however some areas are not covered.\\n\\n5.4 Results\\n\\nThe key objectives of the SAVI architecture were to connect BDI agents to a\\nsimulation platform and resolve the challenges of impedance mismatch associated\\nwith this task.\\n\\n\\n\\nAn Architecture for Integrating BDI Agents with a Simulation Environment 11\\n\\nFig. 3. Scenario 2: Test bed with 10 UAVs with large perception distance and 15\\nthreats.\\n\\nOur simulations were successfully run at several different frame rates, and the\\nagents were able to carry out their task, largely unaffected by these variations.\\nThis demonstrates the suitability of our SAVI architecture to integrate a BDI\\nframework with a simulation platform.\\n\\nAs noted earlier, we wanted to ensure that the agents\\xe2\\x80\\x99 reasoning cycle and\\nthe simulation cycles were decoupled, and that we could manage their relative\\nspeeds. In effect, we needed to be certain that the simulation environment does\\nnot wait for the agent reasoning cycle to complete prior to computing the next\\nsimulation step. Furthermore, it was also of concern to ensure that the agent\\ncannot reason faster than the simulation rate.\\n\\nIn order to demonstrate the effects of our safeguards on the speed coordina-\\ntion, we ran the test scenarios discussed in this case study under various frame\\nrates and measured the effective simulation and reasoning cycle periods. The re-\\nsults for this test are shown in figure 4. The frame rate used as a reference along\\nthe X axis is the requested simulation speed, which may not be achievable in a\\ncomputationally intensive simulation. We therefore plot the effective simulation\\nspeed (measured by the effective period between two frames) and the effective\\nduration of the agents\\xe2\\x80\\x99 reasoning cycles.\\n\\nThe plot shows that the reasoning cycle and the simulation time step follow\\nan identical time step for lower frame rates, below approximately 65 frames per\\nsecond. At these slower simulation speeds, the agent must synchronize its speed\\nto only reason on up-to-date environment perceptions. The decreasing simulation\\n\\n\\n\\n12 Davoust, Gavigan et al.\\n\\ntime step also shows that the simulator is able to achieve the requested frame\\nrate.\\n\\nFig. 4. Difference in simulation time step and reasoning cycle periods at different frame\\nrates.\\n\\nAs the simulation frame rate increases, the simulation time step and the rea-\\nsoning cycle period decrease but begin to diverge, and then they approximately\\nstabilize at the highest speed that the simulator is able to achieve for this sce-\\nnario. At a frame rate of approximately 75 frames per second we can clearly see\\nthe reasoning cycle period lag behind the simulation time step. This means that\\nthe agent is reasoning more slowly than the simulation updates proceed. The\\nsimulated environment is not delayed by a slow agent\\xe2\\x80\\x99s reasoning cycle, and the\\nagent does not develop a backlog of messages (which would affect the agents\\xe2\\x80\\x99\\nperformance and possibly the reasoning speed).\\n\\n6 Conclusion\\n\\nWe have presented the SAVI architecture to integrate multi-agent systems de-\\nveloped using the BDI paradigm with a simulation platform. Our architecture\\ndecouples the execution of a time stepped simulation from the agent\\xe2\\x80\\x99s reasoning\\nprocesses, allowing them to run as separate processes interacting in an asyn-\\nchronous manner. This contributes to a more realistic simulation by allowing the\\nsimulation of environment to proceed regardless of the agents\\xe2\\x80\\x99 decision-making\\nspeed. However, we are nonetheless able to prevent the reasoning cycle from\\n\\n\\n\\nAn Architecture for Integrating BDI Agents with a Simulation Environment 13\\n\\nexecuting faster than the simulation rate. This should not be possible in an en-\\nvironment that is meant to approximate dynamic environments in continuous\\ntime. These benefits of our architecture should make the transition to a natural\\nenvironment more realistic. In addition, the decoupling of the two component\\nframeworks makes it easy to develop them independently, and has allowed our\\nteam to successfully separate these two unrelated concerns during the devel-\\nopment process. We have made our reference implementation available to the\\ncommunity as an open-source project[12].\\n\\nFuture Work\\n\\nAs the SAVI project is under active development, there are several develop-\\nments planned as ongoing and future work. These include the connection of a\\nhuman interface for providing some human command and control for the agent\\nactivities as well as a means for the agents to inform users of the state of the\\nenvironment and as their state. We also want to expand SAVI so that it can run\\nsimulations with reasoners working at reasoning rates tied to the expected per-\\nformance of real embedded reasoning systems. This could also mean connecting\\nSAVI to agents that are loaded on real world hardware, where SAVI would stand\\nin for a real world environment so that real world hardware can be tested in a\\ncontrolled setting. Related to the goal of connecting to real world hardware, the\\nSAVI project currently does not use any analogue sensing of the environment.\\nDevelopment is required in order to support the use agents with simulated ana-\\nlogue sensors which are connected to agents using BDI for higher level reasoning\\nas part of a broader agent architecture.\\n\\nReferences\\n\\n1. Akplogan, M., Quesnel, G., Garcia, F., Joannon, A., Martin-Clouaire, R.: Towards\\na deliberative agent system based on DEVS formalism for application in agricul-\\nture. In: Proceedings of the 2010 Summer Computer Simulation Conference. pp.\\n250\\xe2\\x80\\x93257. SCSC \\xe2\\x80\\x9910, Society for Computer Simulation International, San Diego,\\nCA, USA (2010), http://dl.acm.org/citation.cfm?id=1999416.1999447\\n\\n2. AOSGroup: Jack. http://www.aosgrp.com/products/jack/, accessed: 2019-02-04\\n\\n3. Araujo, F., Valente, J., Al-Zinati, M., Kuiper, D., Zalila-Wenkstern, R.: Divas 4.0:\\nA framework for the development of situated multi-agent based simulation sys-\\ntems. In: Proceedings of the 2013 international conference on Autonomous agents\\nand multi-agent systems. pp. 1351\\xe2\\x80\\x931352. International Foundation for Autonomous\\nAgents and Multiagent Systems (2013)\\n\\n4. Aschermann, M., Kraus, P., Mu\\xcc\\x88ller, J.P.: Lightjason: A bdi framework inspired by\\njason. In: Multi-Agent Systems and Agreement Technologies: 14th Europ. Conf.,\\nEUMAS 2016, and 4rd Int. Conf., AT 2016, Valencia, Spain, 2016. pp. 58\\xe2\\x80\\x9366.\\nSpringer International Publishing (2016)\\n\\n5. Banks, J., Carson, J., Nelson, B., Nicol, D.: Discrete-Event System Simulation.\\nPrentice Hall, 5 edn. (2010)\\n\\n\\n\\n14 Davoust, Gavigan et al.\\n\\n6. Barros, F.J.: Dynamic structure discrete event system specification: A new for-\\nmalism for dynamic structure modeling and simulation. In: Proceedings of the\\n27th Conference on Winter Simulation. pp. 781\\xe2\\x80\\x93785. WSC \\xe2\\x80\\x9995, IEEE Computer\\nSociety, Washington, DC, USA (1995). https://doi.org/10.1145/224401.224731,\\nhttp://dx.doi.org/10.1145/224401.224731\\n\\n7. Ben-Akiva, M., Koutsopoulos, H., Toledo, T., Yang, Q., Choudhury, C., Antoniou,\\nC., Balakrishna, R.: Traffic simulation with mitsimlab. In: Barcelo\\xcc\\x81, J. (ed.)\\nFundamentals of Traffic Simulation, pp. 233\\xe2\\x80\\x93268. Springer New York (2010).\\nhttps://doi.org/10.1007/978-1-4419-6142-6 6, https://doi.org/10.1007/978-1-\\n4419-6142-6 6\\n\\n8. Bergez, J.E., Chabrier, P., Garcia, F., Gary, C., Makowski, D., Quesnel, G., Ra-\\nmat, E., Raynal, H., Rousse, N., Wallach, D.: RECORD: a new software platform\\nto model and simulate cropping systems. Farming System Design, Monterey, CA\\n(2009)\\n\\n9. Bordini, R.H., Hu\\xcc\\x88bner, J.F.: BDI agent programming in agentspeak using jason.\\nIn: Toni, F., Torroni, P. (eds.) Computational Logic in Multi-Agent Systems. pp.\\n143\\xe2\\x80\\x93164. Springer Berlin Heidelberg, Berlin, Heidelberg (2006)\\n\\n10. Bordini, R.H., Hu\\xcc\\x88bner, J.F., Wooldridge, M.: Programming Multi-Agent Systems\\nin AgentSpeak Using Jason (Wiley Series in Agent Technology). John Wiley &#38;\\nSons, Inc., USA (2007)\\n\\n11. Bratman, M.: Intention, plans, and practical reason, vol. 10. Harvard University\\nPress (1987)\\n\\n12. Davoust, A., Gavigan, P., Trabes, C.R.M.A.G., Esfandiari, B., Wainer, G., James,\\nJ.: Simulated autonomous vehicle infrastructure. https://github.com/NMAI-\\nlab/SAVI, accessed: 2019-02-19\\n\\n13. Fry, B., Reas, C.: Processing. https://processing.org/, accessed: 2019-02-16\\n\\n14. Hu\\xcc\\x88bner, J.F., Bordini, R.H.: Jason: a java-based interpreter for an extended version\\nof agentspeak. http://jason.sourceforge.net, accessed: 2019-02-16\\n\\n15. Ingrand, F.F., Georgeff, M.P., Rao, A.S.: An architecture for real-time reasoning\\nand system control. IEEE expert 7(6), 34\\xe2\\x80\\x9344 (1992)\\n\\n16. Jacobs, P.H., Lang, N.A., Verbraeck, A.: D-sol; a distributed java based discrete\\nevent simulation architecture. In: Proceedings of the Winter Simulation Confer-\\nence. vol. 1, pp. 793\\xe2\\x80\\x93800. IEEE (2002)\\n\\n17. Jaworski, P., Edwards, T., Burnham, K.J., Haas, O.C.L.: Microscopic traffic sim-\\nulation tool for intelligent transportation systems. 2012 15th International IEEE\\nConference on Intelligent Transportation Systems pp. 552\\xe2\\x80\\x93557 (2012)\\n\\n18. Kuper, C., Jetbrains, Mu\\xcc\\x88ller, J.P., Spitzer, M., Tatasadi, E.: Lightjason.\\nhttps://lightjason.org/, accessed: 2019-03-15\\n\\n19. Luke, S., Cioffi-Revilla, C., Panait, L., Sullivan, K., Balan, G.: Mason: A multiagent\\nsimulation environment. Simulation 81(7), 517\\xe2\\x80\\x93527 (2005)\\n\\n20. Mittal, Saurabh, Douglass, S.A.: Net-centric act-r-based cognitive architecture\\nwith DEVS unified process. In: Proceedings of the 2011 Symposium on Theory\\nof Modeling & Simulation: DEVS Integrative M&S Symposium. pp. 34\\xe2\\x80\\x9344. TMS-\\nDEVS \\xe2\\x80\\x9911, Society for Computer Simulation International, San Diego, CA, USA\\n(2011), http://dl.acm.org/citation.cfm?id=2048476.2048480\\n\\n21. North, M.J., Howe, T.R., Collier, N.T., Vos, J.R.: A declarative model assembly\\ninfrastructure for verification and validation. In: Takahashi, S., Sallach, D., Rouch-\\nier, J. (eds.) Advancing Social Simulation: The First World Congress, pp. 129\\xe2\\x80\\x93140.\\nSpringer Japan, Tokyo (2007)\\n\\n\\n\\nAn Architecture for Integrating BDI Agents with a Simulation Environment 15\\n\\n22. North, M.J., Collier, N.T., Ozik, J., Tatara, E.R., Macal, C.M., Bragen, M.,\\nSydelko, P.: Complex adaptive systems modeling with repast simphony. Complex\\nAdaptive Systems Modeling 1(1), 3 (Mar 2013). https://doi.org/10.1186/2194-\\n3206-1-3, https://doi.org/10.1186/2194-3206-1-3\\n\\n23. Padgham, L., Scerri, D., Jayatilleke, G., Hickmott, S.: Integrating BDI reasoning\\ninto agent based modeling and simulation. In: Proceedings of the Winter Simu-\\nlation Conference. pp. 345\\xe2\\x80\\x93356. WSC \\xe2\\x80\\x9911, Winter Simulation Conference (2011),\\nhttp://dl.acm.org/citation.cfm?id=2431518.2431555\\n\\n24. Rao, A.S., George, M.P.: BDI agents: From theory to practice. In: Proceedings\\nof the First International Conference on Multi-Agent Systems (ICMAS-95). pp.\\n312\\xe2\\x80\\x93319 (1995), http://www.agent.ai/doc/upload/200302/rao95.pdf\\n\\n25. Ru\\xcc\\x88b, I., Dunin-Ke\\xcc\\xa7plicz, B.: BDI model of connected and autonomous vehicles. In:\\n6th International Workshop on Engineering Multi-Agent Systems (EMAS 2018)\\n(2018), http://emas2018.dibris.unige.it/images/papers/EMAS18-16.pdf\\n\\n26. Russell, S., Norvig, P.: Artificial Intelligence: A Modern Approach, chap. 2.3.2.\\nPrentice Hall Press, Upper Saddle River, NJ, USA, 3rd edn. (2009)\\n\\n27. Singh, D., Padgham, L., Logan, B.: Integrating BDI agents with agent-\\nbased simulation platforms. Autonomous Agents and Multi-Agent Sys-\\ntems 30(6), 1050\\xe2\\x80\\x931071 (Nov 2016). https://doi.org/10.1007/s10458-016-9332-x,\\nhttps://doi.org/10.1007/s10458-016-9332-x\\n\\n28. Tendeloo, Y.V., Vangheluwe, H.: An evaluation of devs simulation tools. SIMU-\\nLATION 93(2), 103\\xe2\\x80\\x93121 (2017). https://doi.org/10.1177/0037549716678330\\n\\n29. Uhrmacher, A.M.: A system theoretic approach to constructing test beds for multi-\\nagent systems. In: Sarjoughian, H.S., Cellier, F.E. (eds.) Discrete Event Modeling\\nand Simulation Technologies: A Tapestry of Systems and AI-Based Theories and\\nMethodologies, pp. 315\\xe2\\x80\\x93339. Springer New York, New York, NY (2001)\\n\\n30. Uhrmacher, A.M., Kullick, B.G.: \\xe2\\x80\\x9dplug and test\\xe2\\x80\\x9d - software agents in\\nvirtual environments. In: 2000 Winter Simulation Conference Proceed-\\nings (Cat. No.00CH37165). vol. 2, pp. 1722\\xe2\\x80\\x931729 vol.2 (Dec 2000).\\nhttps://doi.org/10.1109/WSC.2000.899162\\n\\n31. Van Dyke Parunak, H., Nielsen, P., Brueckner, S., Alonso, R.: Hybrid multi-agent\\nsystems: Integrating swarming and bdi agents. In: Brueckner, S.A., Hassas, S.,\\nJelasity, M., Yamins, D. (eds.) Engineering Self-Organising Systems. pp. 1\\xe2\\x80\\x9314.\\nSpringer Berlin Heidelberg, Berlin, Heidelberg (2007)\\n\\n32. Varga, A., Hornig, R.: An overview of the omnet++ simulation environment.\\nIn: Proceedings of the 1st International Conference on Simulation Tools and\\nTechniques for Communications, Networks and Systems & Workshops. pp. 60:1\\xe2\\x80\\x93\\n60:10. Simutools \\xe2\\x80\\x9908, ICST (Institute for Computer Sciences, Social-Informatics\\nand Telecommunications Engineering), ICST, Brussels, Belgium, Belgium (2008),\\nhttp://dl.acm.org/citation.cfm?id=1416222.1416290\\n\\n33. Wainer, G.: Cd++: a toolkit to develop devs models. Software: Practice and Ex-\\nperience 32(13), 1261\\xe2\\x80\\x931306 (2002). https://doi.org/10.1002/spe.482\\n\\n34. Wilensky, U.: Netlogo. http://ccl.northwestern.edu/netlogo/, Center for Con-\\nnected Learning and Computer-Based Modeling, Northwestern University,\\nEvanston, IL (1999), http://ccl.northwestern.edu/netlogo/\\n\\n35. Zeigler, B.P., Praehofer, H., Kim, T.: Theory of Modelling and Simulation: In-\\ntegrating Discrete Event and Continuous Complex Dynamic Systems. Academic\\nPress, San Diego, CA, USA, 2nd edn. (2000)\\n\\n36. Zhang, Mingxin, Verbraeck, A.: A composable PRS-based agent meta-model\\nfor multi-agent simulation using the DEVS framework. In: Proceedings of the\\n\\n\\n\\n16 Davoust, Gavigan et al.\\n\\n2014 Symposium on Agent Directed Simulation. pp. 1:1\\xe2\\x80\\x931:8. ADS \\xe2\\x80\\x9914, So-\\nciety for Computer Simulation International, San Diego, CA, USA (2014),\\nhttp://dl.acm.org/citation.cfm?id=2665049.2665050\\n\\nAcknowledgement\\n\\nWe acknowledge the support of Cohort Systems, Ottawa, Ontario, Canada.\\nThe work has been partially funded by Department of National Defence\\n\\n(DND) Contract Number: W7714-196749/001/SV.\\nWe acknowledge the support of the Natural Sciences and Engineering Re-\\n\\nsearch Council of Canada (NSERC), [funding reference number 518212].\\nCette recherche a e\\xcc\\x81te\\xcc\\x81 finance\\xcc\\x81e par le Conseil de recherches en sciences na-\\n\\nturelles et en ge\\xcc\\x81nie du Canada (CRSNG), [nume\\xcc\\x81ro de re\\xcc\\x81fe\\xcc\\x81rence 518212].\\n\\n\\n'