b'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAccountability and Agents\\nfor Engineering Business Processes\\n\\nMatteo Baldoni1, Cristina Baroglio1, Olivier Boissier2,\\nRoberto Micalizio1, and Stefano Tedeschi1\\n\\n1 Universita\\xcc\\x80 degli Studi di Torino - Dipartimento di Informatica, Torino, Italy\\nfirstname.lastname@unito.it\\n\\n2 Laboratoire Hubert Curien UMR CNRS 5516, Institut Henri Fayol, MINES Saint-Etienne,\\nSaint-Etienne, France Olivier.Boissier@emse.fr\\n\\nAbstract. Business processes realize a business goal by coordinating the tasks\\nundertaken by multiple interacting parties. Even if it is possible to monitor the\\nexecution of such complex distributed process, current approaches do not allow\\nparticipants to report to the right account taker the causes of the success or failure\\nof their duties. However, as in exception management in programming languages,\\nhaving such information could enable the account taker to properly handle errors.\\nWe claim that an explicit representation of accountability and responsibility as-\\nsumptions provides the right abstractions to engineer multi-agent systems, that\\nexecute such business processes, both at the level of design and at the level of\\nprogramming. Basing our programming approach on multi-agent organizations,\\nwe present two accountability patterns for developing accountable agents. To il-\\nlustrate this approach we use the JaCaMo multi-agent programming platform.\\n\\n1 Introduction\\n\\nWeske [39] defines a business process as \\xe2\\x80\\x9ca set of activities that are performed in coor-\\ndination in an organizational and technical environment. These activities jointly realize\\na business goal.\\xe2\\x80\\x9d In general, a business goal is achieved by breaking it up into sub-\\ngoals, which are distributed to a number of actors. Each actor carries out part of the\\nprocess, and depends on the collaboration of others to perform its task. One limit of\\nbusiness processes is that they integrate, at the same abstraction level, both the business\\nlogic and the interaction logic (message passing). This, on one hand, makes their reuse\\nproblematic\\xe2\\x80\\x93whenever different coordination schemas are to be enacted the business\\nprocess must be revised. On the other hand, since message exchanges lie at the level of\\ndata, it is difficult to assess the correctness of individual processes in isolation.\\n\\nMultiagent Systems (MAS), and in particular models for MAS organizations, are\\npromising candidates to supply the right abstractions to keep processes linked together\\nin a way that allows reasoning about the correctness of the overall system in terms of\\ngoals, rather than of messages. However, agent organizations are still lacking of a sys-\\ntematic way to treat exceptions at execution time. The point is that when an exception\\ndoes occur, the agent which is apt to handle it (or which is interested to know), may be\\nnot the same agent who detects the exception. To make the overall system robust, the\\nexception should be reported to the agent with the proper means for treating it.\\n\\nlouisedennis\\nPlaced Image\\n\\n\\n\\n2 M. Baldoni et al.\\n\\nIn [2] a proposal was made to use accountability and responsibility relationships\\nto state the rights and duties of agents in the organisation, given the specification of a\\nnormative structures. From this understanding we define what it means for an agent to\\nbe accountable when taking responsibilities in the execution of part of a business pro-\\ncess. That is, we address the notion of accountability from a computational perspective\\nand study how it can be obtained as a design property [5]. In the following we show\\nhow robustness can be achieved via accountability and responsibility relationships, and\\nwe use these concepts as tools to systematize and guide the design and development\\nof the agents. We then exemplify how such concepts can be engineered in the partic-\\nular context of a JaCaMo multi-agent system where agents execute under a normative\\norganization expressing business process as accountability and responsibility relations\\namong agents.\\n\\n2 Responsibility and Accountability as Engineering Concepts\\n\\nWhy Should Current BPM and MAO Be Better Engineered\\n\\nIn this paper we consider the Incident Management scenario (from the BPMN examples\\nby the OMG [31]), see Figure 1. The case models the interaction between a customer\\nand a company for the management of a problem reported by the customer. It involves\\nseveral actors. The customer reports the problem to a Key Account Manager who, on\\nthe basis of her experience, can either resolve the problem directly or ask for the in-\\ntervention of first-level support. The problem is, then, recursively treated at different\\nsupport levels until, in the worst case, it is reported to the software developer. Gener-\\nally, the business aim of the process (to solve the reported problem) is decomposed and\\ncan be distributed over five BPMN processes, whose execution requires interaction and\\ncoordination, realized through message exchange. Noticeably, as always with business\\nprocesses, the way in which goals are achieved matters, so the agents that will partici-\\npate into the organization are expected not only to fulfill their assigned goals but also to\\nrespect the business process: from an organizational perspective, the \\xe2\\x80\\x9cgoal\\xe2\\x80\\x9d is that the\\nprocess takes place [1].\\n\\nLimitations/Problems in Current BPM and MAO\\n\\nGoal distribution over a group of processes bears strong similarities with proposals\\nfrom research on MAS organizations. For what concerns software modularity, both\\nbusiness processes and MAS organizations suffer from some limitations and drawbacks;\\nin particular, by focussing merely on the achievement of the assigned sub-goals, agents\\nlose sight of the overall process, and ignore the place of their achievement has within\\nthe organization. So, for instance, in BPMN the relationships between the actors are\\njust loosely modeled via message exchange, and there is no explicit representation of\\nthe responsibilities each of them takes as a party of the interaction nor of the legitimate\\nexpectations each actor has of the others. The relationship between each level of support\\nand the following one, in the example, is emblematic: when a request of support is\\nmade, an answer containing some kind of feedback is expected in order to proceed.\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 3\\n\\nHowever, since processes are independent, one cannot give for granted that another will\\nanswer. It follows that when a process does not answer, the waiting one may get stuck\\nindefinitely.\\n\\nVIP Customer\\nK\\ne\\ny\\n A\\n\\ncc\\no\\nu\\nn\\nt \\n\\nM\\na\\nn\\na\\ng\\ne\\nr\\n\\nCustomer\\nHas Problem\\n\\nExplain\\nSolution\\n\\nAsk\\nDescription\\n\\nAnswer Received\\n\\nCan Handle?\\n\\nAsk 1st Level\\nSupport\\n\\n1\\nst\\n\\n L\\ne\\nv\\ne\\nl \\nS\\nu\\np\\np\\no\\nrt\\n\\nAsk 2nd\\nLevel\\n\\nSupport\\n\\nHandle 1st\\nLevel Issue\\n\\nProvide\\nFeedback for\\n\\nAccount\\nManager\\n\\nAnswer Received\\n\\nResult?\\n\\nIssue\\n\\n2\\nn\\nd\\n L\\n\\ne\\nv\\ne\\nl \\nS\\nu\\np\\np\\no\\nrt\\n\\nResult?\\nProvide\\n\\nFeedback for\\n1st Level\\nSupport\\n\\nHandle 2nd\\nLevel Issue\\n\\nAnswer Received\\n\\nInsert Into\\nProduct\\nBacklog\\n\\nTicket Received\\n\\nUnsure?\\n\\nAsk\\nDeveloper\\n\\nS\\no\\nft\\n\\nw\\na\\nre\\n\\n D\\ne\\nv\\ne\\nlo\\n\\np\\ne\\nr\\n\\nExamine\\nProblem\\n\\nRequest\\nFrom Support\\n\\nProvide\\nFeedback for\\n\\n2nd Level\\nSupport\\n\\nNo\\n\\nYes\\n\\n2nd Level Issue\\n\\nNo Solved\\n\\nSolved\\n\\nYes Next\\nRelease\\n\\nFig. 1: The incident management BPMN diagram.\\n\\nSimilarly, MAO (see, e.g., [12, 16]) allow structuring complex, organizational goal\\nvia a functional decomposition, whereby subgoals are assigned to agents. The coordi-\\nnated execution of subgoals is often supported by a normative specification, with which\\nthe organization issues obligations towards the agents (e.g. [15, 20, 14, 9]). However,\\nagents may have the capability of achieving the assigned goals but in ways that do not\\nfit into the process specification and, more importantly, when agents fail, the organiza-\\ntion has no explicit mechanism for sorting out what occurred, for a redress.\\n\\n\\n\\n4 M. Baldoni et al.\\n\\nEven if agent organizations solve part of the limitation of BPMN, what is actually\\nmissing is the agents\\xe2\\x80\\x99 awareness of their part in the organization, not only in terms of\\nthe goals assigned to them but also (and equally important) in terms of the relationships\\nthey have with the others, of their mutual dependences, and, more broadly, of the de-\\npendence of the organization on its members for what concerns the realization of the\\nbusiness process. We claim that the notions of responsibility and accountability serve\\nthis purpose in an intuitive, yet effective way. A first conceptualization of how these\\nnotions can be used in the context of distributed processes is discussed in [7], here we\\ndiscuss more practical, programming aspects.\\n\\nResponsibility and Accountability\\n\\nAccording to Dubnick [17], accountability \\xe2\\x80\\x9cemerges as a primary characteristic of gov-\\nernance where there is a sense of agreement and certainty about the legitimacy of expec-\\ntations between the community members.\\xe2\\x80\\x9d So, within an institutional frame, account-\\nability manifests as rules, through which authority is \\xe2\\x80\\x9ccontrolled\\xe2\\x80\\x9d so that it is exercised\\nin appropriate ways. In human organizations, it amounts to the enactment of mecha-\\nnisms for dealing with expectations/uncertainty. In complex task environments where\\nmultiple, diverse and conflicting expectations arise, it is a means for managing an other-\\nwise chaotic situation. Further on this line [22], accountability implies that some actors\\nhave the right to hold other actors to a set of standards, to judge whether they have\\nfulfilled their responsibilities in light of these standards, and to impose sanctions if they\\ndetermine that these responsibilities have not been met. They explain that accountabil-\\nity presupposes a relationship between power-wielders and those holding them account-\\nable, where there is a general recognition of the legitimacy of (1) the operative standards\\nfor accountability and (2) the authority of the parties to the relationship (one to exercise\\nparticular powers and the other to hold them to account).\\n\\nConcerning responsibility, [38] proposes an ontology relating six different responsi-\\nbility concepts (capacity, causal, role, outcome, virtue, and liability), that capture: doing\\nthe right thing, having duties, an outcome being ascribable to someone, a condition that\\nproduced something, the capacity to understand and decide what to do, something being\\nlegally attributable. In the context of Information Systems (in particular, access rights\\nmodels and rights engineering methods), the meta-model ReMMO [19] represents re-\\nsponsibility as a unique charge assigned to an agent, and in the cited literature most\\nof the authors acknowledge that responsibility aims at conferring one or more obliga-\\ntion(s) to an actor (the responsibility owner). As a consequence, this causes a moral or\\nformal duty, in the mind of the responsibility owner, to justify the performance of the\\nobligation to someone else, by virtue of its accountability.\\n\\nBusiness processes, represent an agreed behavior, introduce expectations on the be-\\nhavior of the interacting parties, and require some kind of governance in order for the\\nprocess to be enacted. Thus, they show all the characteristics of accountability settings,\\nbut the lack of an adequate representation obfuscates the accountability [30], which re-\\nsults hidden into some kind of collective responsibility \\xe2\\x80\\x93often taking the shape of the so\\ncalled \\xe2\\x80\\x9cmany hands problem\\xe2\\x80\\x9d. As a consequence, the governance of the system is com-\\npromised as well as its functioning as a whole. As Thompson [37] explains, typically\\nadopted solutions for avoiding the many hands problem, like applying hierarchical or\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 5\\n\\ncollective forms of responsibility, are wanting, and personal responsibility approaches,\\nbased on some weak causal connection between an individual and the event, should\\nbe preferred. It is worth noting that accountability and responsibility are not primitive\\nconcepts. Rather, they are properties that emerge in carefully designed software sys-\\ntems. This means that when we use accountability/responsibility as engineering tools,\\nwe actually constrain the ways in which software is designed and developed.\\n\\n3 Engineering MAO with Accountability/Responsibility\\n\\nJaCaMo Organisation Model\\n\\nJaCaMo [10] is a conceptual model and programming platform that integrates agents,\\nenvironments and organizations. A MAS in JaCaMo consists of an agent organization,\\nrealized through MOISE [26], involving Jason [11] autonomous agents, working in\\na shared, artifact-based environment, programmed in CArtAgO [34]. A Jason agent\\nconsists of a set of plans, each having the structure triggering event : \\xe3\\x80\\x88context\\xe3\\x80\\x89 \\xe2\\x86\\x90\\n\\xe3\\x80\\x88body\\xe3\\x80\\x89. On occurrence of triggering event (belief/goal addition or deletion), under the\\ncircumstances given by context, the course of action expressed by body should be taken.\\nMOISE includes an organization modeling language and an organization manage-\\n\\nment infrastructure [25]. The specification of an organization is decomposed into three\\ndimensions. The structural dimension specifies roles, groups and links between roles\\nin the organization. The functional dimension is composed of one (or more) scheme\\ncapturing how the global organizational goal is decomposed into subgoals, and how\\nsubgoals are grouped in sets, called missions, to be distributed to the agents. The nor-\\nmative dimension binds the two previous dimensions by specifying roles\\xe2\\x80\\x99 permissions\\nand obligations for missions.\\n\\nJaCaMo provides various kinds of organizational artifacts that allow encoding the\\nstate and behavior of the organization, in terms of groups, schemes and normative states.\\nObligations are issued on the basis of a normative program, written in NOPL [24].\\nNorms have the form id : \\xcf\\x86 \\xe2\\x86\\x92 \\xcf\\x88, where id is a unique identifier of the norm; \\xcf\\x86 is\\na formula that determines the activation condition for the norm; and \\xcf\\x88 is the conse-\\nquence of the activation of the norm (either a failure or the generation of an obligation).\\nObligations, thus, have a well-defined lifecycle. Once created, an obligation is active.\\nIt becomes fulfilled when the agent, to which the obligation is directed, brings about\\nthe state of the world specified by the obligation before a given deadline. An obliga-\\ntion is unfulfilled when the agent does not bring it about before the deadline. When the\\ncondition \\xcf\\x86 does not hold anymore, the state becomes inactive.\\n\\nAccountability/Responsibility Specifications in the JaCaMo Organisation Model\\n\\nAs introduced in [2], we denote by R(x, q) and A(x, y, r, u) responsibility and ac-\\ncountability relationships, respectively. R(x, q) expresses an expectation on any agent\\nplaying role x on pursuing condition q (x is entitled and should have the capabilities of\\nbringing about q). Instead, A(x, y, r, u) expresses that x, the account-giver (a-giver), is\\n\\n\\n\\n6 M. Baldoni et al.\\n\\naccountable towards y, the account-taker (a-taker), for the condition u when the condi-\\ntion r (context) holds. We see u in the context of r as the agreed standard which brings\\nabout expectations inside the organization.\\n\\nSince the proposal is set into the JaCaMo framework [10], the coordinated execution\\nof the agents is regulated by obligations, issued by the organization. Agents, however,\\nare autonomous and their fulfillment of the obligations cannot be given for granted. In\\n[2], it is therefore proposed to improve the specification of an organization by comple-\\nmenting the functional decomposition of the organizational goal with a set of account-\\nability and responsibility specifications. Precisely, accountability relationships can be\\ncollected in a set A, called an accountability specification. The organization designer\\nwill generally specify a set of accountability specifications which is denoted by A. In\\nthe following, we show in JaCaMo how accountability and responsibility are taken into\\naccount at design time. In particular, we discuss a programming pattern for accountable\\nagents, that is, agents that provide an account of their conduct both when they succeed\\nin achieving their goals, and when, for some reason, they fail in the attempt.\\n\\nTo specify the execution conditions that are object of accountability and responsi-\\nbility, we use the event-based linear logic called precedence logic [35]. Such a language\\nallows modeling complex expressions, under the responsibility of many agents, whose\\nexecution needs to be coordinated. The interpretation deals with occurrences of events\\nalong runs (i.e., sequence of instanced events). Event occurrences are assumed non-\\nrepeating and persistent: once an event has occurred, it has occurred forever. The logic\\nhas three primary operators: \\xe2\\x80\\x98\\xe2\\x88\\xa8\\xe2\\x80\\x99 (choice), \\xe2\\x80\\x98\\xe2\\x88\\xa7\\xe2\\x80\\x99 (concurrence), and \\xe2\\x80\\x98\\xc2\\xb7\\xe2\\x80\\x99 (before). The be-\\nfore operator constrains the order with which two events must occur: a \\xc2\\xb7 b means that\\na must occur before b, but not necessarily one immediately after the other. If e be an\\nevent, e (the complement of e) is also an event. Initially, neither e nor e hold. On any\\nrun, either of the two may occur, not both. Complementary events allow specifying sit-\\nuations in which an expected event e does not occur, either because of the occurrence\\nof an opposite event, or because of the expiration of a time deadline.\\n\\nResiduation, inspired by [29, 35], allows to track the progression of temporal logic\\nexpressions, hopefully arriving to completion of their execution. The residual of a tem-\\nporal expression q with respect to an event e, denoted as q/e, is the remainder temporal\\nexpression that would be left over when e occurs, and whose satisfaction would guar-\\nantee the satisfaction of the original temporal expression q. Residual can be calculated\\nby means of a set of rewrite rules. The following equations are due to Singh [35, 29].\\nHere, r is a sequence expression, and e is an event or >. Below, \\xce\\x93u is the set of liter-\\nals and their complements mentioned in u. Thus, for instance, \\xce\\x93e = {e, e} = \\xce\\x93e and\\n\\xce\\x93e\\xc2\\xb7f = {e, e, f, f}. We have that:\\n\\n0/e\\n.\\n= 0 >/e .= >\\n\\n(r \\xe2\\x88\\xa7 u)/e .= ((r/e) \\xe2\\x88\\xa7 (u/e)) (r \\xe2\\x88\\xa8 u)/e .= ((r/e) \\xe2\\x88\\xa8 (u/e))\\n(e \\xc2\\xb7 r)/e .= r, if e 6\\xe2\\x88\\x88 \\xce\\x93r (e\\xe2\\x80\\xb2 \\xc2\\xb7 r)/e\\n\\n.\\n= 0, if e \\xe2\\x88\\x88 \\xce\\x93r\\n\\nr/e\\n.\\n= r, if e 6\\xe2\\x88\\x88 \\xce\\x93r (e \\xc2\\xb7 r)/e\\n\\n.\\n= 0\\n\\nUsing the terminology in [2], we say that an event e is relevant to a temporal ex-\\npression p if that event is involved in p, i.e. p/e 6\\xe2\\x89\\xa1 p. Let us denote by e a sequence\\ne1, e2, . . . , en of events. We extend the notion of residual of a temporal expression q to\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 7\\n\\na sequence of events e as follows: q/e = (. . . ((q/e1)/e2)/ . . .)/en. If q/e \\xe2\\x89\\xa1 > and\\nall events in e are relevant to q, we say that the sequence e is an actualization of the\\ntemporal expression q (denoted by q\\xcc\\x82).\\n\\nAgent Programming Patterns\\n\\nGiven a set of accountability specifications A, and a set of responsibility assumptions\\nR (responsibility distribution), the organization is properly specified when the account-\\nability fitting \\xe2\\x80\\x9cR fits A\\xe2\\x80\\x9d (denoted by R A) holds. This happens if \\xe2\\x88\\x83 A \\xe2\\x88\\x88 A such that\\n\\xe2\\x88\\x80 A(x, y, r, u) \\xe2\\x88\\x88 A, \\xe2\\x88\\x83 R(x, q) \\xe2\\x88\\x88 R such that, for some actualization q\\xcc\\x82, (u/r)/q\\xcc\\x82 \\xe2\\x89\\xa1 >.\\n\\nFitting has a relevant impact on organization design: When R A holds, any set of\\nagents playing roles into the organization (consistently with R and one accountability\\nspecification A \\xe2\\x88\\x88 A) can actually accomplish the organizational goal, see [2]. More-\\nover, fitting provides a guide for developing agents that are accountable by design, be-\\ncause it expresses what an agent is engaged to achieve, by fulfilling its responsibilities,\\nand how this achievement is related to that process which is the goal of the organization\\n(through accountability). In other words, we claim that R A provides a specification\\nthe agents must explicitly conform to, when enacting organizational roles.\\n\\nWhen an agent enacts some role in an organization, it declares to be aware of all the\\nresponsibilities that come with that role, and by accepting them it declares to adhere to\\nthe fitting exposed by the organization itself. That is, the accountability fitting exposed\\nby an organization specifies the requirements that agents, willing to play roles in that\\norganization, must satisfy.\\n\\nAs seen in Section 2, when an agent accepts a responsibility it accepts to account\\nfor the achievement, or failure, of some state of interest. In our metaphor, thus, an agent\\nacts with the aim of preparing the account it should provide. In this way, we reify the\\ncited \\xe2\\x80\\x9csense of agreement and certainty about the legitimacy of expectations between\\nthe community members\\xe2\\x80\\x9d which otherwise remains implicit both in business processes\\nand in MAS organizations. Leveraging these concepts for developing agents provides\\ninteresting advantages from a software engineering point of view. We now introduce\\ntwo programming patterns that allow realizing accountable agents, but before we need\\nto identify the portion of fitting involving each single individual.\\n\\nDefinition 1. Given the fitting R  A, and a role x in its scope, the projection of the\\nfitting over role x is defined as Rx  Ax where Rx \\xe2\\x89\\xa1 {R(x, q)|R(x, q) \\xe2\\x88\\x88 R}, and\\nAx \\xe2\\x89\\xa1 {A(x, y, r, u)|A(x, y, r, u) \\xe2\\x88\\x88 A}, and where for every A(x, y, r, u) \\xe2\\x88\\x88 Ax, there\\nis R(x, q) \\xe2\\x88\\x88 Rx, such that (u/r)/q\\xcc\\x82 \\xe2\\x89\\xa1 > holds for some actualization q\\xcc\\x82 of q.\\n\\nIndeed, since accountabilities and responsibilities imply some obligations [22], we can\\nthink of realizing them in JaCaMo by relying on the deontic primitive elements that\\nsuch framework provides. In other words, the fitting projection over role x can then\\nbe mapped into a number of Jason plans of the agent playing role x by way of the\\nfollowing patterns, expressed in AgentSpeak(ER). AgentSpeak(ER) [33] extends Jason\\nby introducing two types of plans: g-plans encapsulate the strategy for achieving a goal\\nand can be further structured into sub-plans. Besides triggering events and contexts,\\ng-plans include a goal condition, specifying until when the agent should keep pursuing\\n\\n\\n\\n8 M. Baldoni et al.\\n\\nthe goal. Instead, e-plans, defined in the scope of a g-plan, embody the reactive behavior\\nto adopt while pursuing the g-plan\\xe2\\x80\\x99s goal.\\n\\nDefinition 2 (Pattern Specification). The fitting relationship represented by each pair\\n\\xe3\\x80\\x88R(x, q), A(x, y, r, u)\\xe3\\x80\\x89 in Rx  Ax, is mapped into an AgentSpeak(ER) g-plan ac-\\ncording to the following pattern:\\n\\n+!be accountable(x, y, q) <: drop fitting(x, y, q) {\\n+obligation(x, q) : r \\xe2\\x88\\xa7 c\\n<- bodyq .\\n\\nWell-Doing e-plan\\n\\n+oblUnfulfilled(x, q) : r \\xe2\\x88\\xa7 c\\xe2\\x80\\xb2\\n<- bodyf .\\n\\nWrong-Doing e-plan\\n\\n}\\nSuch that: (1) bodyq satisfies the fitting-adherence condition (see below); (2) bodyf\\nincludes the sending of an explanation for the failure from x to y.\\n\\nThe agent will perceive, through the identity that is provided by the organizational role\\nit plays, certain events as events it should tackle through some behavior of its own, but it\\nwill also be aware of its social position both (1) by knowing some other agent will have\\nthe right, under certain conditions, to ask for an account and (2) by including specific\\nbehavior for building such an account. The two e-plans encode the proactive behavior of\\nan agent assuming a responsibility. From that moment on, and until the responsibility is\\nnot dropped, the agent starts reacting to obligations in accordance to the accountability\\nrelationship specified in the fitting.\\n\\nWell-doing e-plan. The first e-plan is triggered when the specified obligation is issued\\nby the normative organization. That will be the usual obligation a Jason agent receives\\nfrom the MOISE organization when it is time to pursue a particular goal. The con-\\ntext expression, r \\xe2\\x88\\xa7 c, is satisfied when condition r activating the agent accountability\\nholds together with some possibly empty condition c: a local condition that encodes\\nthe possibility for the agent to have multiple well-doing e-plans to react to the same\\nobligation, i.e. multiple ways to achieve a same result in different (local) circumstances\\n(e.g., a manager could decide to handle a task directly or delegate it to an employee).\\nCondition c allows the developer to discriminate between these alternatives, if any. It\\xe2\\x80\\x99s\\nworth noting that if multiple alternative e-plans with different c are present, the devel-\\noper must take care of defining such conditions so that for each obligation issued, at\\nleast one e-plan is always triggered. Due to the accountability fitting the agent has ac-\\ncepted, the body of the plan(s) (bodyq) must,then, be such to satisfy the responsibility\\nassumption represented by the pair \\xe3\\x80\\x88R(x, q), A(x, y, r, u)\\xe3\\x80\\x89. That is, the plan body has\\nto satisfy the following fitting-adherence condition.\\n\\nDefinition 3. (Fitting-adherence) Let [bodyq]u denote the set of sequences of events\\ngenerated by the execution of bodyq , restricted to the events that are relevant for the\\nprogression of u. bodyq satisfies the fitting-adherence condition if: \\xe2\\x88\\x83 sequence s \\xe2\\x88\\x88\\n[bodyq]u such that s \\xe2\\x89\\xa1 q\\xcc\\x82 and (u/r)/q\\xcc\\x82 \\xe2\\x89\\xa1 >.\\n\\nNote that fitting adherence requires the agent to be just able to activate at least one\\nactualization s of q, not all of them. In other words, the agent needs to be able to\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 9\\n\\nperform at least one of the possibly many ways for carrying out q. The rationale is that\\nany actualization of q generates a sequence of events that brings the condition u/r to\\n>; hence, it is sufficient for an agent to implement one actualization in order to meet its\\nresponsibility. As we have discussed above, an accountable agent provides an account of\\nits conduct. In our framework, the account of a well-doing pattern is immediately given\\nby the agent\\xe2\\x80\\x99s behavior itself. Following Garfinkel [21], we consider that the account, or\\nproof, that the agent behaved correctly is evident by how the agent has operated in the\\nenvironment. This means that the obligation to give an account for the satisfaction of\\nan obligation is implicitly resolved by satisfying the very same obligation. Thus, there\\nis not the need to capture the obligation to give an account explicitly. When, however,\\nit is not possible to see the agent\\xe2\\x80\\x99s operations as a proof, an explicit account should\\nbe provided also for the well-doing case. This, for instance, happens when there is the\\nneed of reporting facts that occur in one context, but are meaningful also in others where\\nthey are not directly observable by the involved parties, see e.g., [4]. It is also the case\\nin which an agent\\xe2\\x80\\x99s behavior requires some certification for having been performed up\\nto some standard. It is interesting to note that the accountability fitting is not only a\\nfunctional specification of the organization, but it also specifies the \\xe2\\x80\\x9cgood\\xe2\\x80\\x9d behavior of\\nthe agents. It is in fact this characteristic that justifies our programming patterns, and\\nthat it is not captured in standard JaCaMo.\\n\\nWrong-doing e-plan. The second pattern allows the agent to provide an account also\\nwhen the agent does not complete a task, for some reason. The triggering event, oblUn-\\nfulfilled, is generated by theMOISE organization when a previously issued obligation\\nhas been left unsatisfied. The context of the pattern is again a condition that is true when\\nthe accountability is activated (i.e., r holds), and when some local condition c\\xe2\\x80\\xb2 is satis-\\nfied. bodyf , this time, has to produce an account about the failure. We can think of such\\nan account as an explanation that the agent produces so that another agent, possibly the\\na-taker y, can use it to resume the execution, thus managing the exception. The correct\\nuse of the pattern guarantees, by design, that exceptional events, when occurring, are\\nreported to the agents who can handle them properly. Accountability fulfills this pur-\\npose because, by nature, it brings about an obligation on the a-giver to give an account\\nof what it does. The account, then, can be used by the a-taker to recover, when possi-\\nble, from the exceptional situation. Under this respect, the account should be provided\\nin terms that can be understood by all the interested agents in the organization. This\\naspect, however, is strongly domain dependent. As well as in the positive pattern, the\\nagent will produce an account by modifying its environment in a way that is meaningful\\nfor the agents that have to capture and interpret it.Along this line, a promising approach\\nto the synthesis of an account is discussed in [13].\\n\\n4 JaCaMo Accountable Agents\\n\\nIn JaCaMo, the state of an organization is encoded in terms of group instances (i.e.,\\nwhich agents are playing which roles) and scheme instances (i.e., which goals were\\nachieved, which ones are ready to be pursued, etc). Notably, such scheme instances are\\ndeclarative in nature: they only specify which (sub)goals should be achieved, and in\\n\\n\\n\\n10 M. Baldoni et al.\\n\\nwhich order, but they do not specify how. By exploiting these instances, the organiza-\\ntion issues proper obligations to role players (i.e., agents). The agents are autonomous\\nin the way they satisfy their obligations, and may also use artifacts that are not globally\\naccessible to all the involved agents. They are, however, held to notify the organization\\nabout the completion of their task (see the use of goalAchieved messages in Section 4).\\nBy capturing these messages, the organization traces the subgoals that have been com-\\npleted and determine the next obligations to be issued.\\n\\nThe engineering ofMOISE accountable organizations involves the following steps3:\\n1. Each process is mapped to a role in the organization;\\n2. A scheme representing the overall process goal is defined; the successful execution\\n\\nof such a scheme corresponds to the achievement of the process goal;\\n3. For each activity to be performed in sequence, a corresponding subgoal is added to\\n\\nthe scheme, by means of the corresponding operator;\\n4. For each structured block including a concurrent execution, the corresponding goals,\\n\\ngrouped together via the parallel operator, are added to the scheme;\\n5. If a choice is present inside a process, a number of schemes should be defined,\\n\\nrepresenting the possible courses of action. These schemes are to be instantiated\\ndynamically by the agents, depending on their internal choices. Their execution\\nconcurs to the progression of the already present ones.\\n\\nBy applying the steps above to Incident Management we obtain the following. For\\nwhat concerns the structural specification, five roles are identified, all belonging to a\\nsingle group: customer (c), key account manager (am), first level support (fls), second\\nlevel support (sls), and developer (dev). For each problem to manage, we assume there\\nwill be exactly one agent playing each role. Moreover, we use the label company to\\nidentify the owner of the specified organization.\\n\\nThe overall organizational goal is distributed into a set of schemes, part of which\\nis reported in Figure 2. The scheme on top involves c and am, and is instantiated by\\nthe customer c when some need arises. In other terms, the scheme instantiation corre-\\nsponds to the occurrence of a report-problemc event. When a problem is reported, the\\naccount manager is expected to perform ask-descriptionam (ask for a description of the\\nproblem), and c to send what requested (send-descriptionc). Then, am should provide\\na solution: to this aim, it can take two alternatives courses of action, both leading to\\nthe same join point of the BPMN diagram. Each path amounts to a new scheme, that\\nwill be instantiated by the agent depending on the choice made. Only by completing\\nthe execution of the selected scheme the outer scheme will progress. Here, the first al-\\nternative amounts to the case in which am can handle the problem directly, and does\\nnot require the execution of any action before the join point. For this reason, the cor-\\nresponding scheme would be empty and we omit it. The second scheme, instead, is\\ninstantiated when am cannot handle the problem directly. Thus, it will, first, make a\\nrequest (ask-support-flsam) that fls will either manage directly or will involve the next\\nlevel of support by instantiating a further scheme. It is worth noting that scheme in-\\nstantiation is not used just to tackle situations in which one agent needs to interact with\\n\\n3 Here we restrict our attention to the translation of structured blocks (see [18]) into social\\nschemes. The presence of a single exit point is necessary to ensure the proper completion of\\ntheMOISE schemes.\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 11\\n\\nfirst-level-management\\n\\nproblem-management\\n\\nask-descriptionam send-descriptionc explain-solutionam\\n\\n. . .\\n\\nhandle-issue-1fls provide-feedback-amflsask-support-flsam\\n\\ncannot-handleam\\n\\nresult-slsfls\\n\\nreport-problemc\\n\\nFig. 2: Part of the functional decomposition of Incident Management.\\n\\na1 : A(am, c, report-problemc, report-problemc \\xc2\\xb7 ask-descriptionam)\\na2 : A(am, c, report-problemc \\xc2\\xb7 ask-descriptionam \\xc2\\xb7 send-descriptionc, report-problemc \\xc2\\xb7 ask-descriptionam\\xc2\\xb7\\n\\xc2\\xb7send-descriptionc \\xc2\\xb7 explain-solutionam)\\n\\na3 : A(am, company, report-problemc, report-problemc \\xc2\\xb7 ask-descriptionam)\\na4 : A(am, company, report-problemc \\xc2\\xb7 ask-descriptionam \\xc2\\xb7 send-descriptionc, report-problemc \\xc2\\xb7 ask-descriptionam\\xc2\\xb7\\n\\xc2\\xb7send-descriptionc \\xc2\\xb7 explain-solutionam)\\n\\na5 : A(am, company, report-problemc \\xc2\\xb7 ask-descriptionam \\xc2\\xb7 send-descriptionc \\xc2\\xb7 cannot-handleam, report-problemc\\xc2\\xb7\\n\\xc2\\xb7ask-descriptionam \\xc2\\xb7 send-descriptionc \\xc2\\xb7 cannot-handleam \\xc2\\xb7 ask-support-flsam)\\n\\n. . .\\n\\nr1 : R(am, ask-descriptionam) r2 : R(am, explain-solutionam) r3 : R(am, ask-support-flsam)\\n. . .\\n\\nFig. 3: Excerpt of the accountability specification and responsibility distribution for the Incident\\nManagement scenario.\\n\\nothers for some aim, but it may also occur when a process has internal choices. This\\ndepends on whether the single branches are subject to accountabilities or not, that is,\\nwhether the agent should not only achieve the goal, but also stick to the specified pro-\\ncess in doing so. This is, for instance, the case of the second choice in the Second Level\\nSupport process (see \\xe2\\x80\\x9cResult?\\xe2\\x80\\x9d in Figure 1).\\n\\nInterestingly, the instantiation \\xe2\\x80\\x9con-the-fly\\xe2\\x80\\x9d of a scheme can be seen as a form of\\nplanning autonomy: \\xe2\\x80\\x9cThis type of autonomy dictates if an agent is able (or unable) to\\ncreate, choose or modify plans to achieve a specific goal\\xe2\\x80\\x9d [27]. The integration of this\\ntype of autonomy into an organizational model (i.e.,MOISE) discussed in [27] opens\\ninteresting perspectives in the modeling of BPMN processes for our accountable agents.\\n\\nFigure 3 reports an excerpt of an accountability specification Aincident for the inci-\\ndent management scenario. Accountabilities a1-a5, in particular concern am as a-taker.\\nThe first accountability a1 states that am is accountable towards c for asking for a de-\\n\\n\\n\\n12 M. Baldoni et al.\\n\\nscription, only after a problem is reported. To guarantee this strict ordering, the event\\nreport-problemc appears both as the antecedent condition and as a prefix of the conse-\\nquent condition, preceding ask-descriptionam (the same structure is used throughout the\\nsubsequent relationships). This requirement means that c can legitimately expect that,\\nby reporting a problem to am, it will be asked for a description of the problem. The\\nsecond accountability, similar to the previous one, states that once the description of the\\nproblem has been provided, am must, in the end, explain the solution, no matter what\\nhappens in the meanwhile.\\n\\nAccountabilities a3-a5 encode the fact that all workers, inside the incident manage-\\nment company, are expected to stick to the process specification. For this reason, these\\naccountabilities do not include the customer c, who is not an employee of the com-\\npany. Indeed, in the BPMN representation the customer process is collapsed. The only\\nrequirement that should be captured by the accountability specification concerns the\\nproper interaction with am. In a4, explain-solutionam is the exit point of the structured\\nblock beginning with the XOR gateway (see Figure 1). The accountability means that,\\nno matter what path is chosen, the agent must account (either positively or negatively)\\nabout the achievement of that task. This accountability is, then, complemented with a5,\\nwhich states that if am decides it cannot handle the problem directly (cannot-handleam),\\nthen it will execute ask-support-flsam. In a way, cannot-handleam manifests the internal\\nchoice made by the agent, and will lead to the instantiation of the second social scheme\\ndiscussed above. These five accountability, a1-a5, completely characterize the am agent.\\n\\nWith the accountability specification Aincident as a basis, the designer can iden-\\ntify a suitable responsibility distribution which fits it. An excerpt of an acceptable one,\\nw.r.t. am, is reported in Figure 3. It is easy to verify that for each ai \\xe2\\x88\\x88 Aam there\\nis a rj \\xe2\\x88\\x88 Ram which fits it. For instance, if we consider a1 and r1, we have that:\\n(report-problemc \\xc2\\xb7 ask-descriptionam)/report-problemc/ ask-descriptionam \\xe2\\x89\\xa1 >.\\n\\nEngineering Accountability Behaviors in Agents\\n\\nAs an illustration, we briefly explain the realization of the key account manager am\\nagent. We restrict our attention to Aam = {a1, a2, a3, a4, a5} and Ram = {r1, r2, r3}.\\nFor each pair in Ram  Aam, a g-plan must be defined, containing the proper well-\\ndoing and wrong-doing e-plans. Let us consider, in particular, the fitting involving r2  \\na2 implemented by the following plans.\\n\\n1 +!be_accountable(Ag,ATaker,What)\\n2\\n\\n3 : .my_name(Ag) &\\n4 (satisfied(sch1,explain_solution) = What |\\n5 done(sch1,explain_solution,Ag) = What) &\\n6 play(ATaker,customer,incident_group)\\n7\\n\\n8 <: drop_fitting(Ag,ATaker,What) {\\n9\\n\\n10 +obligation(Ag,_,What,_)[artifact_id(ArtId)]\\n11 : .my_name(Ag) & (satisfied(sch1,explain_solution) = What |\\n12 done(sch1,explain_solution,Ag)=What) &\\n13 goalState(sch1,ask_description,_,_,satisfied) &\\n14 goalState(sch1,send_description,_,_,satisfied) &\\n15 play(Customer,customer,incident_group) & can_handle(What)\\n16 <- println(\"Explaining solution...\");\\n17 .send(Customer,tell,explain_solution);\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 13\\n\\n18 goalAchieved(explain_solution)[artifact_id(ArtId)].\\n19\\n\\n20 +obligation(Ag,_,What,_)[artifact_id(ArtId)]\\n21 : .my_name(Ag) & (satisfied(sch1,explain_solution) = What |\\n22 done(sch1,explain_solution,Ag)=What) &\\n23 goalState(sch1,ask_description,_,_,satisfied) &\\n24 goalState(sch1,send_description,_,_,satisfied) &\\n25 play(Customer,customer,incident_group) &\\n26 not can_handle(What) &\\n27 orgArt(OrgArtId) & grArt(GrArtId)\\n28 <- createScheme(sch2, scheme2, SchArtId)[artifact_id(OrgArtId)];\\n29 debug(inspector_gui(on))[artifact_id(SchArtId)];\\n30 focus(SchArtId); addScheme(sch2)[artifact_id(GrArtId)];\\n31 ?goalState(sch2,provide_feedback_am,_,_,satisfied)[artifact_id(SchArtId)];\\n32 .send(Customer,tell,explain_solution);\\n33 goalAchieved(explain_solution)[artifact_id(ArtId)].\\n34\\n\\n35 +oblUnfulfilled(O)\\n36 : .my_name(Ag) & obligation(Ag,_,What,_) = O &\\n37 (satisfied(sch1,explain_solution) = What |\\n38 done(sch1,explain_solution,Ag)=What) &\\n39 goalState(sch1,ask_description,_,_,satisfied) &\\n40 goalState(sch1,send_description,_,_,satisfied) &\\n41 can_handle(What)\\n42 <- .send(ATaker, tell, operation_failed_error).\\n43\\n\\n44 +oblUnfulfilled(O)\\n45 : .my_name(Ag) & obligation(Ag,_,What,_) = O &\\n46 (satisfied(sch1,explain_solution) = What |\\n47 done(sch1,explain_solution,Ag)=What) &\\n48 goalState(sch1,ask_description,_,_,satisfied) &\\n49 goalState(sch1,send_description,_,_,satisfied) &\\n50 not can_handle(What) &\\n51 not goalState(sch2,provide_feedback_am,_,_,satisfied) &\\n52 <- .send(ATaker, tell, please_call_again).\\n53\\n\\n54 +cancel-fls-request\\n55 : oblUnfulfilled(O) & obligation(_,_,What,_) = O &\\n56 (satisfied(sch2,provide_feedback_am) = What |\\n57 done(sch2,provide_feedback_am,_)=What) &\\n58 <- .send(ATaker, tell, please_call_Again);\\n59 .drop_all_intentions.\\n60 ...\\n61 }\\n\\nThe outer g-plan is triggered when the agent proactively decides to adhere to the\\nfitting r2  a2, thereby becoming accountable for the task. Once triggered, the g-plan\\nwill remain active until the agent does not drop the fitting (see Line 8). The plans in\\nbraces encode the reactive behavior corresponding to the well-doing and wrong-doing\\ne-plans specified by the pattern. The first two plans, in particular, realize the well-doing\\npart of the pattern. Recalling Definition 2, the plans are triggered as soon as an obli-\\ngation to explain the solution to the customer\\xe2\\x80\\x99s problem is issued (Line 10). The obli-\\ngation\\xe2\\x80\\x99s object (What) is the satisfaction of the organizational goal explain solution\\n(Lines 11 and 12) \\xe2\\x80\\x93corresponding to the explain-solutionam event in Figure 3. Indeed,\\nin JaCaMo, the achievement of an organizational goal fulfills the corresponding obli-\\ngation. Then, as requested by the pattern, the contexts of both plans must include the\\nconditions specified in a2. In JaCaMo we represent these conditions in terms of schemes\\nthat were instantiated and in terms of organizational goals that were achieved. Consider-\\ning the fitting-adherence condition, we have that r is report-problemc\\xc2\\xb7ask-descriptionam\\xc2\\xb7\\nsend-descriptionc, and u is report-problemc \\xc2\\xb7 ask-descriptionam \\xc2\\xb7 send-descriptionc \\xc2\\xb7\\n\\n\\n\\n14 M. Baldoni et al.\\n\\nexplain-solutionam. Thus q \\xe2\\x89\\xa1 u/r is just explain-solutionam. Both plans for well-doing,\\nthus, need to include some actions that amount to such an event. In this setting we\\nconsider the event explain-solutionam to be occurred as soon as the corresponding orga-\\nnizational goal is set as achieved. This is trivially true in the example (see Lines 18 and\\n33). Here, the achievement of the goal is notified to the organization after the construc-\\ntion of the answer to the customer (represented in the code by a simple print in one case,\\nand by the interaction with fls in the other). Agent acts by modifying the organizational\\nenvironment. This leads to the construction of a sequence of facts that constitutes the\\naccount for the specific goal.\\n\\nThe presence of two plans triggered by the same obligation reflects the internal\\nchoice inside the business process, driven by some local condition. The first plan is ex-\\necuted when am can handle the problem directly (Line 15): the solution to the problem\\nis simply sent to the customer and the corresponding organizational goal is marked as\\nachieved. The second plan, instead, is executed when the agent decides to ask for sup-\\nport (Line 26). In this case, before providing a feedback to the customer the agent will\\ncreate an instance of the second social scheme (Line 28), thereby making its choice\\n(cannot-handleam) public. The successful scheme completion will provide it with a\\nfeedback from fls (Line 31): am can legitimately expect such a feedback by virtue of\\naccountability a7, in which it is a-taker. The feedback, in turn, will enable the agent to\\nexecute explain-solutionam, by setting the organizational goal as achieved and produc-\\ning an actualization of the formula in the obligation, as discussed above.\\n\\nThe third and fourth plans, at Lines 35 and 44, instead, deal with the wrong-doing\\npart of the pattern. Should, for any reason, the obligation be unfulfilled, the agent, by\\nvirtue of its accountabilities, must provide a motivation about the unsatisfaction of the\\nobligation to the account-taker. The plan at Line 35, in particular, is triggered when the\\nobligation is unfulfilled because of a reason that is internal to the am agent itself (e.g.,\\nthe plan at Line 15 was triggered, but not successfully completed). The fourth plan,\\ninstead, at Line 44, is triggered when the obligation becomes unfulfilled because am\\nis still waiting for a feedback from sls. In both cases, a proper message encoding the\\nexplanation for the failure is sent to the a-taker (see Lines 42 and 52).\\n\\nThe last plan, at Line 54, in turn exemplifies how am behaves as an a-taker when\\nreceives the account of a failure from another (a-giver) agent. Specifically, the plan\\nhandles a possible failure coming from fls raised when it has not satisfied its obligation\\nto provide a feedback. Event cancel-fls-request corresponds to the message\\nfls sends as an account of such a failure, and am handles such a failure by asking the\\ncustomer to call another time and dropping its current intention(s).\\n\\nNotably, considering the accountability specification as a requirement, the actual\\nimplementation of the system results more robust. The accountable am for instance,\\ncan be rewritten in BPMN as shown in Figure 4: to satisfy the requirement of being\\naccountable, am must be capable, on the one side, of capturing exceptions from other\\nagents (specifically, fls), and on the other side, of providing an account to its a-taker\\n(i.e., the customer). The other processes are modified in a similar way.\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 15\\nIncident Management as detailed\\ncollaboration\\n\\nVIP Customer\\n\\nK\\ney\\n\\n A\\ncc\\n\\no\\nu\\n\\nn\\nt \\n\\nM\\nan\\n\\nag\\ner\\n\\nKey Account Manager\\n\\nCustomer Has a Problem\\n\\nGet Problem\\nDescription\\n\\nExplain\\nSolution\\n\\nAnswer ReceivedCan Handle it Myself?\\n\\nAsk 1st Level\\nSupport\\n\\nCancel 1st level\\nsupport\\nrequest\\n\\n1 day\\n\\nInvite to recall\\n\\n1s\\nt \\n\\nLe\\nve\\n\\nl S\\nu\\n\\np\\np\\n\\no\\nrt\\n\\n A\\nge\\n\\nn\\nt\\n\\n1st Level Support Agent\\n\\nAsk 2nd Level\\nSupport\\n\\nHandle 1st\\nLevel Issue\\n\\nProvide\\nFeedback for\\n\\nAccount\\nManager\\n\\nAnswer Received\\n\\nResult?\\n\\nIssue\\n\\nCancel 2nd level\\nsupport request\\n\\n1 day\\n\\nExplain failure\\n1st level support\\n\\n2n\\nd\\n\\n L\\nev\\n\\nel\\n S\\n\\nu\\np\\n\\np\\no\\n\\nrt\\n A\\n\\nge\\nn\\n\\nt\\n\\n2nd Level Support Agent\\n\\nResult?\\nProvide\\n\\nFeedback for\\n1st Level\\nSupport\\n\\nHandle 2nd\\nLevel Issue\\n\\nAnswer Received\\n\\nInsert Into\\nProduct\\nBacklog\\n\\nAsk Developer\\n\\nTicket Received\\n\\nUnsure?\\n\\nSome issues cannot\\nget fixed right but\\nshould be in next\\nrelease\\n\\nSometimes opinion\\nof development is\\nneeded\\n\\n1 day\\n\\nExplain failure\\n2nd level\\nsupport\\n\\nCancel software\\ndeveloper\\nsupport\\n\\nSo\\nft\\n\\nw\\nar\\n\\ne \\nD\\n\\nev\\nel\\n\\no\\np\\n\\ner Examine\\nProblem\\n\\nRequest From\\nSupport\\n\\nProvide Feedback\\nfor 2nd Level\\n\\nSupport\\n\\n1 day\\nExplain failure\\n\\nsoftware\\ndeveloper\\nsupport\\n\\nYes\\n\\nNo\\n\\n2nd Level Issue\\n\\nIssue Resolved\\n\\nNo\\n\\nFix in Next Release\\n\\nIssue Resolved\\n\\nYe\\ns\\n\\nFig. 4: The accountable process of Account Manager.\\n\\n5 Conclusions\\n\\nIn this paper we have focused on the development of accountable agents. So, we have\\ndiscussed how the accountability/responsibility specification of an organization can be\\nmapped into two patterns for programming Jason plans. The two patterns, when ap-\\nplied systematically, bring along positive consequences. First of all, an accountabili-\\nty/responsibility specification provides a programmer with all the relevant information\\nfor developing an agent that is aware of the process as characterization of the goal. In\\nfact, while a responsibility distribution is a coverage of the functional decomposition,\\nan accountability specification conveys the programmer how the agent being developed\\ncontributes to the process. Hence, the accountabilities provide the programmer with a\\nbehavioral specification the agent has to satisfy.\\n\\nOur approach is specular to [40], where the objective is to determine whether a\\ngroup of agents can be attributed the responsibility for a given goal. Once the respon-\\nsibility can be attributed to the agents, their accountability is implicitly modeled in\\nthe plan that has be inferred. Here, instead, we aim at developing agents that, by con-\\nstruction, satisfy the organization specification. Indeed, an interesting evolution of the\\npresent work goes in the direction of an agent-oriented type checking (see e.g., [3]).\\nHaving an explicit model of the organization in terms of accountabilities and responsi-\\nbilities, it would be possible to mechanize a type checking system that verifies whether,\\nat role enacting time, an agent possesses all the necessary plans for role playing.\\n\\nThe proposal moves MAOs closer to other paradigms where exceptions are handled.\\nIn the actor model (e.g., [23]), for instance, when an actor cannot handle an exception, it\\nusually reports the exception to its parent actor, which in turns decides to either handle\\nthe exception or report it further. In an agent-based system such a scheme is not directly\\napplicable since agents are independent entities, and rarely are related to each other by a\\nparent-child relationship. In the MAS community, approaches for modeling exceptions\\nin a multi-agent setting have been proposed (see, e.g., [28, 36, 32]). However, no con-\\nsensus has been reached w.r.t. the usage of such a concept in agent systems. The main\\nproblems rise when trying to accomodate the usual exception handling semantics with\\n\\n\\n\\n16 M. Baldoni et al.\\n\\nthe properties of MAS; namely autonomy, openness, heterogeneity, and encapsulation.\\nAccountabilities can fill in this gap: when an obligation is not satisfied, it is reasonable\\nto report the exception to the a-taker (see above example). This is achieved quite natu-\\nrally with the Wrong-Doing Pattern, that allows an agent to provide an account for an\\nunsatisfied obligation.\\n\\nCommitment-based protocols (e.g., [41]), as well as standard NorMAS [8], provide\\nalternatives for modeling coordination. Roughly speaking, a commitment is a promise\\nthat a debtor does in favor to a creditor that in case some antecedent condition is satis-\\nfied, the debtor will bring about a consequent condition. When the antecedent holds, the\\ncommitment is detached, and amounts to an obligation on the debtor to bring about the\\nconsequent. When the consequent is no longer achievable, the commitment is violated.\\nIn such a case, the creditor has the right to complain against the debtor, the creditor\\ncannot hold the debtor to provide an explanation. This lack of information hampers\\nboth the understanding of what has occurred, and any attempt of recovery from the fail-\\nure. However, commitments have the power of enforcing accountability when properly\\nused. For instance, the ADOPT protocol [6] establishes an accountability relationship,\\nexpressed via a commitment-based protocol, between an organization and its agents.\\n\\nReferences\\n\\n1. Adamo, G., Borgo, S., Di Francescomarino, C., Ghidini, C., Guarino, N.: On the notion of\\ngoal in business process models. In: Ghidini, C., Magnini, B., Passerini, A., Traverso, P.\\n(eds.) AI*IA 2018 - Advances in Artificial Intelligence - XVIIth International Conference\\nof the Italian Association for Artificial Intelligence, Trento, Italy, November 20-23, 2018,\\nProceedings. Lecture Notes in Computer Science, vol. 11298, pp. 139\\xe2\\x80\\x93151. Springer (2018)\\n\\n2. Baldoni, M., Baroglio, C., Boissier, O., May, K.M., Micalizio, R., Tedeschi, S.: Account-\\nability and responsibility in agent organizations. In: PRIMA 2018: Principles and Practice\\nof Multi-Agent Systems, 21st International Conference. Lecture Notes in Computer Science,\\nvol. 11224, pp. 261\\xe2\\x80\\x93278. Springer (2018)\\n\\n3. Baldoni, M., Baroglio, C., Capuzzimati, F., Micalizio, R.: Type Checking for Protocol Role\\nEnactments via Commitments. Journal of Autonomous Agents and Multi-Agent Systems\\n32(3), 349\\xe2\\x80\\x93386 (May 2018)\\n\\n4. Baldoni, M., Baroglio, C., Chopra, A.K., Singh, M.P.: Composing and Verifying\\nCommitment-Based Multiagent Protocols. In: Wooldridge, M., Yang, Q. (eds.) Proc. of\\n24th International Joint Conference on Artificial Intelligence, IJCAI 2015. Buenos Aires,\\nArgentina (July 25th-31th 2015), http://ijcai-15.org/\\n\\n5. Baldoni, M., Baroglio, C., May, K.M., Micalizio, R., Tedeschi, S.: Computational Account-\\nability. In: Chesani, F., Mello, P., Milano, M. (eds.) Deep Understanding and Reasoning:\\nA challenge for Next-generation Intelligent Agents, URANIA 2016. vol. 1802, pp. 56\\xe2\\x80\\x93\\n62. CEUR, Workshop Proceedings, Genoa, Italy (December 2016), http://ceur-ws.org/Vol-\\n1802/paper8.pdf\\n\\n6. Baldoni, M., Baroglio, C., May, K.M., Micalizio, R., Tedeschi, S.: Computational Account-\\nability in MAS Organizations with ADOPT. Applied Sciences 8(4) (2018)\\n\\n7. Baldoni, M., Baroglio, C., Micalizio, R.: Goal Distribution in Business Process Models.\\nIn: Ghedini, C., Magnini, B., Passerini, A., Traverso, P. (eds.) Proc. of 17th International\\nConference of the Italian Association for Artificial Intelligence (AI*IA 2018). Lecture Notes\\nin Computer Science, vol. 11298, pp. 252\\xe2\\x80\\x93265. Springer, Trento, Italy (2018)\\n\\n\\n\\nAccountability and Agents for Engineering Business Processes 17\\n\\n8. Boella, G., van der Torre, L.W.N., Verhagen, H.: Introduction to normative multiagent sys-\\ntems. In: Normative Multi-agent Systems. Dagstuhl Seminar Proceedings, vol. 07122 (2007)\\n\\n9. Boissier, O., Bordini, R.H., Hu\\xcc\\x88bner, J.F., Ricci, A., Santi, A.: Multi-agent ori-\\nented programming with JaCaMo. Sci. Comput. Program. 78(6), 747\\xe2\\x80\\x93761 (2013).\\nhttps://doi.org/10.1016/j.scico.2011.10.004\\n\\n10. Boissier, O., Bordini, R.H., Hu\\xcc\\x88bner, J.F., Ricci, A., Santi, A.: Multi-agent oriented program-\\nming with JaCaMo. Science of Computer Programming 78(6), 747\\xe2\\x80\\x93761 (2013)\\n\\n11. Bordini, R.H., Hu\\xcc\\x88bner, J.F., Wooldridge, M.: Programming Multi-Agent Systems in AgentS-\\npeak Using Jason. John Wiley & Sons (2007)\\n\\n12. Corkill, D.D., Lesser, V.R.: The use of meta-level control for coordination in distributed\\np roblem solving network. In: Bundy, A. (ed.) Proceedings of the 8th International Joint\\nConference on Ar tificial Intelligence (IJCAI\\xe2\\x80\\x9983). pp. 748\\xe2\\x80\\x93756. William Kaufmann, Los\\nAltos, CA (1983)\\n\\n13. Cranefield, S., Oren, N., Vasconcelos, W.: Accountability for practical reasoning agents. In:\\nAT 2018: 6th International Conference on Agreement Technologies. LNCS, Springer (2018),\\naccepted/In press\\n\\n14. Dastani, M., Tinnemeier, N.A., Meyer, J.J.C.: A programming language for normative multi-\\nagent systems. In: Handbook of Research on Multi-Agent Systems: semantics and dynamics\\nof organizational models, pp. 397\\xe2\\x80\\x93417. IGI Global (2009)\\n\\n15. Dignum, V.: A model for organizational interaction: based on agents, founded in logic. Ph.D.\\nthesis, Utrecht University (2004), published by SIKS\\n\\n16. Dignum, V.: Handbook of research on multi-agent systems: Semantics and dynamics of or-\\nganizational models (2009)\\n\\n17. Dubnick, M.J., Justice, J.B.: Accounting for accountability (September 2004),\\nhttps://pdfs.semanticscholar.org/b204/36ed2c186568612f99cb8383711c554e7c70.pdf,\\nannual Meeting of the American Political Science Association\\n\\n18. Dumas, M., Garc\\xc4\\xb1\\xcc\\x81a-Ban\\xcc\\x83uelos, L., Polyvyanyy, A.: Unraveling unstructured process models.\\nIn: Mendling, J., Weidlich, M., Weske, M. (eds.) Business Process Modeling Notation. pp. 1\\xe2\\x80\\x93\\n7. Springer Berlin Heidelberg, Berlin, Heidelberg (2010)\\n\\n19. Feltus, C.: Aligning Access Rights to Governance Needs with the Responsability MetaModel\\n(ReMMo) in the Frame of Enterprise Architecture. Ph.D. thesis, University of Namur, Bel-\\ngium (2014)\\n\\n20. Fornara, N., Vigano\\xcc\\x80, F., Verdicchio, M., Colombetti, M.: Artificial institutions: a model of\\ninstitutional reality for open multiagent systems. Artificial Intelligence and Law 16(1), 89\\xe2\\x80\\x93\\n105 (2008). https://doi.org/10.1007/s10506-007-9055-z\\n\\n21. Garfinkel, H.: Studies in ethnomethodology. Prentice-Hall Inc., Englewood Cliffs, New Jer-\\nsey (1967)\\n\\n22. Grant, R.W., Keohane, R.O.: Accountability and Abuses of Power in World Politics. The\\nAmerican Political Science Review 99(1) (2005)\\n\\n23. Haller, P., Sommers, F.: Actors in Scala - concurrent programming for the multi-core era.\\nArtima (2011)\\n\\n24. Hu\\xcc\\x88bner, J.F., Boissier, O., Bordini, R.H.: A normative organisation programming language\\nfor organisation management infrastructures. In: Padget, J., Artikis, A., Vasconcelos, W.,\\nStathis, K., da Silva, V.T., Matson, E., Polleres, A. (eds.) Coordination, Organizations, In-\\nstitutions and Norms in Agent Systems V. pp. 114\\xe2\\x80\\x93129. Springer Berlin Heidelberg, Berlin,\\nHeidelberg (2010)\\n\\n25. Hu\\xcc\\x88bner, J.F., Boissier, O., Kitio, R., Ricci, A.: Instrumenting multi-agent organisations with\\norganisational artifacts and agents. Autonomous Agents and Multi-Agent Systems 20(3),\\n369\\xe2\\x80\\x93400 (5 2010)\\n\\n\\n\\n18 M. Baldoni et al.\\n\\n26. Hu\\xcc\\x88bner, J.F., Sichman, J.S., Boissier, O.: Developing organised multiagent systems using the\\nMOISE+ model: Programming issues at the system and agent levels. Int. J. Agent-Oriented\\nSoftw. Eng. 1(3/4), 370\\xe2\\x80\\x93395 (2007)\\n\\n27. Maia, A., Sichman, J.S.: Explicit representation of planning autonomy in MOISE organiza-\\ntional model. In: 7th Brazilian Conference on Intelligent Systems, BRACIS 2018, Sa\\xcc\\x83o Paulo,\\nBrazil, October 22-25, 2018. pp. 384\\xe2\\x80\\x93389 (2018)\\n\\n28. Mallya, A.U., Singh, M.P.: Modeling exceptions via commitment protocols. In: Proceed-\\nings of the Fourth International Joint Conference on Autonomous Agents and Multiagent\\nSystems. pp. 122\\xe2\\x80\\x93129. AAMAS \\xe2\\x80\\x9905, ACM (2005)\\n\\n29. Marengo, E., Baldoni, M., Baroglio, C., Chopra, A., Patti, V., Singh, M.: Commitments with\\nregulations: reasoning about safety and control in REGULA. In: Proc. of the 10th Int. Conf.\\non Autonomous Agents and Multiagent Systems (AAMAS). vol. 2, pp. 467\\xe2\\x80\\x93474 (2011)\\n\\n30. Nissenbaum, H.: Accountability in a computerized society. Science and Engineering Ethics\\n2(1), 25\\xe2\\x80\\x9342 (1996)\\n\\n31. Object Management Group: Bpmn specification - business process model and notation\\n(2018), http://www.bpmn.org/, online, accessed 08/11/2018\\n\\n32. Platon, E., Sabouret, N., Honiden, S.: An architecture for exception management in multia-\\ngent systems. Int. J. Agent-Oriented Softw. Eng. 2(3), 267\\xe2\\x80\\x93289 (2008)\\n\\n33. Ricci, A., Bordini, R.H., Hu\\xcc\\x88bner, J.F., Collier, R.: AgentSpeak(ER): An Extension of\\nAgentSpeak(L) improving Encapsulation and Reasoning about Goals. In: AAMAS. pp.\\n2054\\xe2\\x80\\x932056. International Foundation for Autonomous Agents and Multiagent Systems Rich-\\nland, SC, USA / ACM (2018)\\n\\n34. Ricci, A., Piunti, M., Viroli, M., Omicini, A.: Environment Programming in CArtAgO, pp.\\n259\\xe2\\x80\\x93288. Springer US, Boston, MA (2009)\\n\\n35. Singh, M.P.: Distributed Enactment of Multiagent Workflows: Temporal Logic for Web Ser-\\nvice Composition. In: The Second International Joint Conference on Autonomous Agents\\n& Multiagent Systems, AAMAS 2003, July 14-18, 2003, Melbourne, Victoria, Australia,\\nProceedings. pp. 907\\xe2\\x80\\x93914. ACM (2003)\\n\\n36. Souchon, F., Dony, C., Urtado, C., Vauttier, S.: Improving exception handling in multi-agent\\nsystems. In: Software Engineering for Multi-Agent Systems II. pp. 167\\xe2\\x80\\x93188. Springer Berlin\\nHeidelberg (2004)\\n\\n37. Thomson, J.J.: Remarks on causation and liability. Philosophy and Public Affairs 13(2),\\n101\\xe2\\x80\\x93133 (1984)\\n\\n38. Vincent, N.A.: Moral Responsibility, Library of Ethics and Applied Philosophy, vol. 27,\\nchap. A Structured Taxonomy of Responsibility Concepts. Springer (2011)\\n\\n39. Weske, M.: Business Process Management: Concepts, Languages, Architectures. Springer\\n(2007)\\n\\n40. Yazdanpanah, V., Dastani, M.: Distant group responsibility in multi-agent systems.\\nIn: PRIMA 2016: Princiles and Practice of Multi-Agent Systems - 19th International\\nConference, Phuket, Thailand, August 22-26, 2016, Proceedings. pp. 261\\xe2\\x80\\x93278 (2016).\\nhttps://doi.org/10.1007/978-3-319-44832-9 16\\n\\n41. Yolum, P., Singh, M.P.: Commitment Machines. In: Intelligent Agents VIII, 8th Int. WS,\\nATAL 2001. LNCS, vol. 2333, pp. 235\\xe2\\x80\\x93247. Springer (2002)\\n\\n\\n'