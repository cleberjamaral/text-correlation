b'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Does It Take to Create Social Awareness\\nfor Support Agents??\\n\\nIlir Kola1, Catholijn M. Jonker1,2, and M. Birna van Riemsdijk1,3\\n\\n1 Interactive Intelligence group, Delft University of Technology, The Netherlands\\n2 Leiden Institute of Advanced Computer Science, The Netherlands\\n\\n3 Human Media Interaction lab, University of Twente, The Netherlands\\n{i.kola, m.b.vanriemsdijk, c.m.jonker}@tudelft.nl\\n\\nAbstract. Social awareness is a property that agents should have in\\norder to support humans in their activities, especially if that advice might\\nimpact on the social relationships of their users. This paper describes the\\nresearch method and the expected contributions of research that aims to\\nanswer the following question: What knowledge structures and reasoning\\ntechniques can enable behaviour support agents to take into account the\\nuser\\xe2\\x80\\x99s social situation when offering support?. In particular we anticipate\\nto produce a two-layer ontology of social situations, a mechanism to\\nreason about the influence of the situation on the behaviour of the user,\\nand a mechanism to reason about the social implications of possible\\nbehaviours and thus advice the user on the best course of action.\\n\\nKeywords: Socially aware agents \\xc2\\xb7 Social situation modelling \\xc2\\xb7 Research\\nmethodologies\\n\\n1 Introduction\\n\\nArtificial agents that help people live healthier lifestyles or form certain habits\\nare becoming a reality. These behaviour support agents mostly focus on mod-\\nelling internal aspects of the users (e.g. their goals, values etc.), while neglecting\\nthe role of the context in which the users are in. For example, an online search\\nperformed in the autumn of 2018 showed that the most downloaded apps that\\nhelp users quit smoking take into account the cigarette consumption, daily goals\\netc., but do not consider elements of the environment which lead to smoking.\\n\\nIn social psychology, the concept of situations is used when talking about\\nelements of the environment, and research shows that the situation affects the\\nbehaviour of people. Situations have a physical and a social aspect. In computer\\nscience, while there is some work on modelling the physical aspect of situa-\\ntion (e.g. [20]), the social part is still missing. We define socially aware support\\nagents as agents which are able to take into account the social situation the\\nuser is in. According to this definition, current support agents are not able to\\n\\n? This work is part of the research programme CoreSAEP (project no. 639.022.416),\\nsupported by the Netherlands Organisation for Scientific Research (NWO)\\n\\nlouisedennis\\nPlaced Image\\n\\n\\n\\n2 Kola et al.\\n\\nprovide socially aware support. In this project we do not focus on building a\\ncomplete behaviour support agent, but rather on exploring reasoning techniques\\nthat would allow behaviour support agents to take the social situation into ac-\\ncount when offering support. Based on this, the overarching research question of\\nthis project is the following:\\n\\nWhat knowledge structures and reasoning techniques can enable behaviour\\nsupport agents to take into account the user\\xe2\\x80\\x99s social situation when of-\\nfering support?\\n\\nIn this article, we will explore the research steps needed to answer this ques-\\ntion. The rest of the article is structured as follows: section 2 argues why social\\nsituations are important for behaviour support agents. In section 3 we review\\nrelated work and position ourselves. Section 4 introduces our approach, as well\\nas discusses the methodology and expected contributions. Section 5 concludes\\nthe article.\\n\\n2 Motivation\\n\\nIn this section, we argue why the ability to model and reason about social sit-\\nuations is crucial for behaviour support agents. First we will argue about the\\nimportance of situations and their connection to human behaviour and social\\nrelations from the point of view of social psychology. Next, we discuss how these\\nconcepts have been reflected in artificial intelligence so far.\\n\\nAccording to [10], the influence of situations on human behaviour traces back\\nto the pioneering work of Kurt Lewin [13, 14], who posited that human behaviour\\nis a function of personality and the surrounding environment, whereas the pre-\\nvious trends had only focused on behaviour being influenced by personality.\\nThis idea has been followed by sociologists when modelling social interactions.\\nKenny\\xe2\\x80\\x99s Social Relations Model [11] proposes that social relations are a function\\nof the actor effect, the partner effect, the relationship effect and the \\xe2\\x80\\x9coccasion\\xe2\\x80\\x9d\\neffect. In a similar spirit, interdependence theory (e.g., [8]) argues that the In-\\nteraction (I) that occurs between two people (A and B) is a function of their\\nrespective tendencies in relation to each other in the particular situation of in-\\nterdependence (S) in which the interaction occurs. This work suggests that an\\nartificial agent that supports a human user needs to be able to model the social\\naspect of situations in order to be able to offer sensible support.\\n\\nCarley and Newell [2], already in 1994, proposed the building blocks that are\\nneeded to build an artificial social agent. They argue that a social agent should\\nhave information-processing capabilities and knowledge. The former are goal\\noriented and depend on the agent\\xe2\\x80\\x99s internal capabilities. Knowledge is dictated\\nby the environment. The authors argue that agents exist in particular situations\\n(both physical and social), but how much of this situation is encoded by the\\nagent and how it is encoded, is an open issue. In the past years, most work\\nhas focused on the information-processing capabilities of the agents, and there\\nhas been considerable success in building cognitive agent architectures (e.g. [7],\\n\\n\\n\\nCreating Social Awareness for Support Agents 3\\n\\n[17]). On the other hand, approaches that model situations have mostly focused\\non the physical aspects of the environment. Most of these attempts are part of\\nthe work on situation awareness (e.g. [6]). This line of research focuses more\\non emergency situations and is task oriented. Therefore, it lacks the tools that\\nwould enable agents to model daily life situations, which often have a social\\nnature. The importance of tackling this issue is accepted in the community.\\nFor example, Kaminka [9] argues that agent systems should incorporate general\\nsocial intelligence building blocks, and Dignum et al. [5] suggest that the next\\nstep in artificial intelligence is the ability to show social intelligent behaviour. Our\\nresearch aims at closing this gap. Other related work which attempts at doing\\nthis is discussed in the next section, where we position our work in relation to\\nthese approaches.\\n\\n3 Related Work\\n\\nWe are not the first to research how to enable behaviour support agents to\\noffer socially adaptive help. Social Practices are proposed by Dignum and\\ncolleagues [3, 4] as a way to reason about support in a social context. This\\napproach is based on the sociological concept of social practices [19], which\\ntries to establish a link between practice and their social context. In [4], Dignum\\net al. propose to represent social practices by using physical context (resources,\\nplaces, actors), social context (social interpretation, roles, norms), activities, plan\\npatterns, meaning and competences. In turn, these social practices can inform\\nthe agent about the expectations in a given setting. This approach is not very\\ndifferent from ours, since we are also reasoning about what is expected from\\nan agent in a social situation. However, their main contribution is on \\xe2\\x80\\x9chow the\\nagent uses practices in its deliberation and planning\\xe2\\x80\\x9d [3], while the set of social\\npractices is considered to be a given one. In our approach we model the social\\nrelationships as well as the elements of the situation explicitly by using input\\nfrom the user as well as sensory data, and use these models in order to reason\\nabout what is expected from the user in that situation.\\n\\nPlatys Social is an approach proposed by Murukannaiah et al. [15] to add\\nsocial context in artificial agents. They link the concept of places with the amount\\nof interaction that the user has with other people in order to identify social\\ncircles of the user. For example, individuals that are met at the user\\xe2\\x80\\x99s home are\\nmost probably the family members. The interaction with other people is detected\\nfrom Bluetooth data as well as amount of calls or messages, while in order to link\\ngeographical positions to conceptual places and activities that take place in those\\nplaces, they use an ontology-based approach [20]. While the concept of places can\\nplay a role in determining part of the social environment, we think this is not\\nenough to capture all aspects of a social relationships. For example, a person\\nmight be attending a work dinner in a restaurant, however, seen statistically,\\nthe restaurant as a conceptual place could be linked to a casual social setting.\\nMoreover you might have had limited or no contact with the other attendees\\nbefore the dinner, so the system would give a low priority to the connections,\\n\\n\\n\\n4 Kola et al.\\n\\nwhich does not match with the fact that the meeting is actually very important.\\nFurthermore, we believe that only relying on sensor data is not enough to fully\\ncapture the subjective point of view of the user, this is why in our approach\\nrelying on input from the user is one of the core concepts.\\n\\nAjmeri and colleagues [1] propose Arnor, a method that allows the imple-\\nmentation of privacy aware socially intelligent personal agents by using social\\nconstructs. Arnor\\xe2\\x80\\x99s steps include modelling goals, the environmental context, the\\nsocial expectations, and the social experience of the user. However, the way in\\nwhich the environmental context is modelled seems to be implicit. The authors\\nsay \\xe2\\x80\\x9cThe social context could include the place where the interaction occur, at-\\ntributes of the place, neighbors in the vicinity, the social relationship between\\nprimary and secondary stakeholders, the activities the stakeholders are involved\\nin, and so on\\xe2\\x80\\x9d. All these are indeed potentially important elements of the so-\\ncial context, however at this point they seem to be selected ad-hoc for specific\\nexample scenarios.\\n\\nWe think our proposed framework is a middle ground of these approaches.\\nOn the one hand, we agree with the approach of Social Practices and Arnor\\nthat modelling the social environment requires representing many nuances (ac-\\ntors, roles, social interpretations etc.). However, we also think that considering\\nthese social elements as given is not enough if we consider real life applications,\\ntherefore it is important to have explicit knowledge structures which define the\\nelements of the environment that have to be represented, like it is done in the\\nPlatys Social approach.\\n\\n4 Proposed Approach\\n\\nAs aforementioned, situation awareness literature offers ways how to model the\\nenvironment and reason about that knowledge. Although that work is not aimed\\nat social situations, we can use their proposed concepts as an inspiration. One\\nof the most accepted frameworks for situation awareness is the one proposed by\\nEndsley [6]. This framework consists of three levels:\\n\\n\\xe2\\x80\\x93 Level 1 is perception, and involves capturing the status, attributes, and\\ndynamics of relevant elements in the environment;\\n\\n\\xe2\\x80\\x93 Level 2 is comprehension, which deals with understanding the significance\\nof elements in the environment, beyond just being aware of their existence;\\n\\n\\xe2\\x80\\x93 Level 3 is projection, which is the ability to project the future status of the\\nelements of the environment, based on levels 1 and 2.\\n\\nInspired by these levels, we believe that a behaviour support agent should also\\nbe able to represent relevant aspects of social situations, be able to reason about\\ntheir meaning, and lastly project how these situations will affect the behaviour\\nof the user. Once this process is completed, we call the agent socially aware, and\\nthe agent can support the user while taking this information into account.\\n\\nIn the following subsections we will introduce the methodology that we plan\\nto apply throughout our research in order to achieve this vision, and the contri-\\nbutions we expect to make.\\n\\n\\n\\nCreating Social Awareness for Support Agents 5\\n\\n4.1 Methodology\\n\\nTo tackle our research question, within this project, we will follow these steps:\\n\\n1. Explore relevant literature from social science in order to base our approach\\non grounded theoretical models;\\n\\n2. Organise these concepts in formal knowledge structures;\\n3. Propose reasoning techniques that can be used to infer new information from\\n\\nthe elements of the knowledge structure;\\n4. Conduct user studies to evaluate whether the knowledge structure and rea-\\n\\nsoning techniques can be used in real scenarios.\\n\\nWe believe that basing our approach on formalizing concepts from social sciences\\nshould make it more useful in practice. This methodology is often used in the\\nagents community (e.g. [3]). However, we are aware that concepts from social\\nsciences are debated in the social sciences, much in the same way as artificial\\nintelligence is debated by artificial intelligence researchers. As we cannot be sure\\nto have selected an accurate model for our application domain, step four tests\\nthe practical validity of our proposed methods.\\n\\nOur approach is user-centered rather than data-driven. As a result, instead\\nof having a large amount of data, an approach which can raise ethical concerns\\nregarding privacy, we will follow the less is more paradigm: only capture the\\ninformation that together with the user the agent determines to be useful to\\nhelp the user in the way they wish to be helped.\\n\\n4.2 Contributions\\n\\nAs aforementioned, the main contribution of this project will be to provide\\nknowledge structures and reasoning techniques that allow behaviour support\\nagents to take into account the user\\xe2\\x80\\x99s social situation before offering support.\\nTo illustrate our points, we will use the following scenario: Bob has a support\\nagent which helps him be more punctual, and he has a meeting with his boss,\\nAlice. Our contribution will consist in answering the following questions:\\n\\n(1) What knowledge structures can represent the user\\xe2\\x80\\x99s social situation?\\nThe first step towards enabling behaviour support agents to reason about\\n\\nsocial situations is to decide which elements of the environment have to be rep-\\nresented. To tackle this issue we explore literature on social relationships and\\nsituation cues. Based on that, we propose a two-level ontology that can be used\\nto model social situations. The upper level represents general concepts which\\napply to all social situations, and the lower one contains more specific domain-\\ndependent features. In [12], we propose a set of features that can be used to model\\neveryday social situations involving two people, and we evaluate our approach\\nvia a pilot study. In our scenario, we would model the role of Alice towards Bob,\\nthe level of formality in the relationship, the quality of the relationship, the type\\nof meeting that they have etc.\\n\\n\\n\\n6 Kola et al.\\n\\n(2) How can support agents reason about the characteristics of a situation?\\nHaving elements of a situation is useful, however at this stage they are just\\n\\nabstract concepts which do not have any meaning. Behaviour support agents\\nshould be able to identify how these elements relate to each other and what do\\nthese interactions mean for the user. Social psychology literature refers to this\\nas defining the psychological characteristics of the situation, and they are seen\\nas different dimensions of a situation. In our scenario, we would infer that the\\nmeeting has a high level of duty and intellect, a low level of humor etc. There\\nare different taxonomies of situations (e.g. [16], [18]), so our first step will be to\\nidentify which dimensions to use and how to structure that knowledge. Then we\\nwill propose reasoning techniques which can help us assess these dimensions of\\nthe situation, and in turn build the situation profile.\\n\\n(3) How can support agents reason about what behaviour is expected from the\\nuser and what values are promoted in a certain situation?\\n\\nOnce we have a situation profile consisting of different dimensions relevant\\nto the situation, in order to be able to provide support, we need to know how\\ndoes the situation profile translate into what is expected in that type of situa-\\ntion. Social psychology research (e.g. the work of [18]) explores the correlation\\nof situation dimensions with different behaviours and values that are promoted.\\nThis will serve as our theoretical background, and we will provide appropriate\\nreasoning techniques which can deal with that information. In our scenario, the\\nsituation suggests that Bob is expected to be on time and prepared for the meet-\\ning, and that this meeting would promote his career development.\\n\\n(4) How can an agent that is aware of the social situation best advice its user?\\nUntil now we talked about how can we enable a behaviour support agent to\\n\\nassess a situation and reason about its characteristics. In order for the agent to\\nactually provide support, there are two steps that need to be taken. The first\\nstep consists of detecting cases where support is actually needed. To achieve\\nthat, we can use as input the expected behaviour and values on one hand (from\\nresearch question 3), and the user\\xe2\\x80\\x99s personal values and commitments on the\\nother. Then, the agent can reason about how to support the user. Going back\\nto our example, the agent notices that Bob is expected to be on time for the\\nmeeting, and on the other hand it knows Bob has problems with being punctual.\\nSince this meeting promotes Bob\\xe2\\x80\\x99s values, it sends him an early reminder.\\n\\n5 Concluding\\n\\nIn this article, we discuss steps that are needed in order to enable support agents\\nto take into account the user\\xe2\\x80\\x99s social situation. However, this is just a starting\\npoint. Hopefully, you will read this article while we are still working on these\\nsteps, to stay updated visit our website1. If so, please feel free to join us, or reach\\nout to us if you have comments, ideas or similar research interests.\\n\\n1 http://ii.tudelft.nl/coresaep/\\n\\n\\n\\nCreating Social Awareness for Support Agents 7\\n\\nReferences\\n\\n1. Ajmeri, N., Murukannaiah, P.K., Guo, H., Singh, M.P.: Arnor: Modeling social\\nintelligence via norms to engineer privacy-aware personal agents. In: Proceedings\\nof the 16th Conference on Autonomous Agents and MultiAgent Systems. pp. 230\\xe2\\x80\\x93\\n238 (2017)\\n\\n2. Carley, K., Newell, A.: The nature of the social agent. Journal of mathematical\\nsociology 19(4), 221\\xe2\\x80\\x93262 (1994)\\n\\n3. Dignum, F.: Interactions as social practices: towards a formalization. arXiv preprint\\narXiv:1809.08751 (2018)\\n\\n4. Dignum, V., Dignum, F.: Contextualized planning using social practices. In: In-\\nternational Workshop on Coordination, Organizations, Institutions, and Norms in\\nAgent Systems. pp. 36\\xe2\\x80\\x9352. Springer (2014)\\n\\n5. Dignum, V., Jonker, C.M., Prada, R., Dignum, F.: Situational Deliberation; Get-\\nting to Social Intelligence. Computational Social Science and Social Computer\\nScience: Two Sides of the Same Coin (2014)\\n\\n6. Endsley, M.R.: Toward a theory of situation awareness in dynamic systems. Human\\nFactors 37(1), 32\\xe2\\x80\\x9364 (1995)\\n\\n7. Franklin, S., Kelemen, A., McCauley, L.: Ida: A cognitive agent architecture. In:\\nSMC\\xe2\\x80\\x9998 Conference Proceedings. 1998 IEEE International Conference on Systems,\\nMan, and Cybernetics (Cat. No. 98CH36218). vol. 3, pp. 2646\\xe2\\x80\\x932651. IEEE (1998)\\n\\n8. Holmes, J.G.: Social relationships: The nature and function of relational schemas.\\nEuropean Journal of Social Psychology 30(4), 447\\xe2\\x80\\x93495 (2000)\\n\\n9. Kaminka, G.A.: Curing robot autism: A challenge. In: Proceedings of the 2013\\ninternational conference on Autonomous agents and multi-agent systems. pp. 801\\xe2\\x80\\x93\\n804 (2013)\\n\\n10. Kelley, H.H., Holmes, J.G., Kerr, N.L., Reis, H.T., Rusbult, C.E., Van Lange, P.A.:\\nAn atlas of interpersonal situations. Cambridge University Press (2003)\\n\\n11. Kenny, D.A., La Voie, L.: The social relations model. Advances in experimental\\nsocial psychology 18, 142\\xe2\\x80\\x93182 (1984)\\n\\n12. Kola, I., Jonker, C.M., Van Riemsdijk, M.B.: Who\\xe2\\x80\\x99s that? - Modelling Social Situa-\\ntions for Behaviour Support Agents. Manuscript submitted for publication. (2019)\\n\\n13. Lewin, K.: Principles of topological psychology. New York, NY: McGraw Hill (1936)\\n14. Lewin, K.: Field theory and experiment in social psychology: Concepts and meth-\\n\\nods. American journal of sociology 44(6), 868\\xe2\\x80\\x93896 (1939)\\n15. Murukannaiah, P.K., Singh, M.P.: Platys social: Relating shared places and private\\n\\nsocial circles. IEEE Internet Computing 16(3), 53\\xe2\\x80\\x9359 (2012)\\n16. Parrigon, S., Woo, S.E., Tay, L., Wang, T.: Caption-ing the situation: A lexically-\\n\\nderived taxonomy of psychological situation characteristics. Journal of personality\\nand social psychology 112(4), 642 (2017)\\n\\n17. Rao, A.S., Georgeff, M.P.: Modeling rational agents within a bdi-architecture. KR\\n91, 473\\xe2\\x80\\x93484 (1991)\\n\\n18. Rauthmann, J.F., Gallardo-Pujol, D., Guillaume, E.M., Todd, E., Nave, C.S., Sher-\\nman, R.A., Ziegler, M., Jones, A.B., Funder, D.C.: The situational eight diamonds:\\nA taxonomy of major dimensions of situation characteristics. Journal of Personality\\nand Social Psychology 107(4), 677 (2014)\\n\\n19. Reckwitz, A.: Toward a theory of social practices: A development in culturalist\\ntheorizing. European journal of social theory 5(2), 243\\xe2\\x80\\x93263 (2002)\\n\\n20. Zavala, L., Murukannaiah, P.K., Poosamani, N., Finin, T., Joshi, A., Rhee, I.,\\nSingh, M.P.: Platys: From position to place-oriented mobile computing. AI Maga-\\nzine 36(2), 50\\xe2\\x80\\x9362 (2015)\\n\\n\\n'